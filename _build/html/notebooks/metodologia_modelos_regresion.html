

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Modelos de Regresión &#8212; Analisis de localidades y aprovechamiento solar en Barranquilla: Análisis climático por localidad y estimación del potencial energético</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/metodologia_modelos_regresion';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Modelos de clasificación" href="metodologia_modelos_clasificacion.html" />
    <link rel="prev" title="Exploración de Datos (EDA)" href="eda.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Analisis de localidades y aprovechamiento solar en Barranquilla: Análisis climático por localidad y estimación del potencial energético - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Analisis de localidades y aprovechamiento solar en Barranquilla: Análisis climático por localidad y estimación del potencial energético - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Contextualización:
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="eda.html">Exploración de Datos (EDA)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Modelos de Regresión</a></li>
<li class="toctree-l1"><a class="reference internal" href="metodologia_modelos_clasificacion.html">Modelos de Clasificación</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/YisusParker/jbook_ml20251" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/metodologia_modelos_regresion.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Modelos de Regresión</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#librerias"><strong>Librerias:</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-problema-evaluacion-del-potencial-de-energia-solar-en-barranquilla-analisis-de-irradiancia-y-variables-atmosfericas-para-la-generacion-sostenible"><strong>Caso problema: Evaluación del potencial de energía Solar en Barranquilla: Análisis de irradiancia y variables atmosféricas para la generación sostenible</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contextualizacion"><strong>Contextualización</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-para-el-caso-de-regresion-y-benchmark"><strong>Modelos para el caso de regresión y Benchmark</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knn"><strong>KNN</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion"><strong>Evaluación</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-del-modelo"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-resultados-numericos"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-visual-actual-vs-predicted"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lineal-regression"><strong>Lineal Regression</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evalucion"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id2"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-regressor"><strong>SVM Regressor</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><strong>Análisis del modelo</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression"><strong>Ridge Regression</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id9"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id10"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id11"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso-regression"><strong>Lasso Regression</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id12"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id13"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id14"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id15"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id16"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest"><strong>Random Forest</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id17"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id18"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id19"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id20"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id21"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost"><strong>XGBoost</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id22"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id23"><strong>Análisis del modelo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id24"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id25"><strong>Análisis Visual (Actual vs Predicted)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id26"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resultados"><strong>Resultados</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-grafica-de-los-modelos"><strong>Comparacion grafica de los modelos</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id27"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-finales-del-analisis-de-modelos-de-regresion"><strong>Conclusiones Finales del Análisis de Modelos de Regresión</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id28"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id29"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-segun-r2-bondad-de-ajuste">Comparación según R² (Bondad de ajuste)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id30"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id31"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-segun-mse-error-cuadratico-medio">Comparación según MSE (Error Cuadrático Medio)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id32"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id33"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-segun-mae-error-absoluto-medio">Comparación según MAE (Error Absoluto Medio)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id34"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id35"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-segun-tiempo-de-entrenamiento">Comparación según Tiempo de Entrenamiento</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id36"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id37"></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#recomendacion-final"><strong>Recomendación Final</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id38"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-and-lasso-regression-optimized"><strong>Ridge and Lasso Regression (optimized)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-lasso-y-ridge-mejorados"><strong>Análisis de Lasso y Ridge mejorados:</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-de-modelos-lineales-antes-vs-despues-de-la-optimizacion"><strong>Comparación de Modelos Lineales: Antes vs Después de la Optimización</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression-optimizado">1. Ridge Regression (Optimizado)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso-regression-optimizado">2. Lasso Regression (Optimizado)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-comparativa">Conclusión Comparativa</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knn-and-regression-optimized"><strong>KNN and Regression (optimized)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analsis-de-regresion-lineal-y-knn-mejorados"><strong>Análsis de Regresion lineal y KNN mejorados</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-de-modelos-lineal-y-knn-antes-vs-despues-de-la-optimizacion"><strong>Comparación de Modelos: Lineal y KNN - Antes vs Después de la Optimización</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-con-y-sin-polynomialfeatures">1. Linear Regression (con y sin PolynomialFeatures)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbors-knn">2. K-Nearest Neighbors (KNN)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id39">Conclusión Comparativa</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-final-con-todos-los-modelos-optimizados-y-no-optimizados"><strong>Análisis final con todos los modelos optimizados y no optimizados</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-final"><strong>Conclusion final</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graficas-de-comparacion"><strong>Gráficas de Comparación</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-global"><strong>Conclusión Global</strong></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="modelos-de-regresion">
<h1><strong>Modelos de Regresión</strong><a class="headerlink" href="#modelos-de-regresion" title="Permalink to this heading">#</a></h1>
<section id="librerias">
<h2><strong>Librerias:</strong><a class="headerlink" href="#librerias" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing PolynomialFeatures for generating polynomial and interaction features</span>
<span class="c1"># Importing RepeatedKFold for repeated cross-validation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">RepeatedKFold</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="c1"># importinng linear_model for linear regression</span>


<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVR</span>
<span class="c1"># Importing SVR for Support Vector Regression</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="c1"># Importing KNeighborsRegressor for k-nearest neighbors regression</span>

<span class="c1"># Importing pandas for data manipulation and analysis</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="c1"># Importing seaborn for data visualization</span>

<span class="c1"># Importing matplotlib.pyplot for creating visualizations</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Importing time module for measuring execution time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="c1"># Importing cross_val_score for cross-validation scoring</span>

<span class="c1"># Importing train_test_split for splitting data into training and testing sets</span>
<span class="c1"># Importing GridSearchCV for hyperparameter tuning using grid search</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>

<span class="c1"># Importing Pipeline for creating machine learning pipelines</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># Importing StandardScaler for feature scaling</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># Importing Ridge and Lasso for linear regression with regularization</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span>

<span class="c1"># Importing RandomForestRegressor for ensemble-based regression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Importing XGBRegressor from XGBoost for gradient boosting regression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBRegressor</span>

<span class="c1"># Importing metrics for evaluating regression models</span>
<span class="c1"># r2_score: Coefficient of determination</span>
<span class="c1"># mean_squared_error: Mean squared error</span>
<span class="c1"># mean_absolute_error: Mean absolute error</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the dataset from the specified file path</span>
<span class="c1"># Ensure the file path is correct and accessible</span>
<span class="c1"># Use relative paths cautiously to avoid issues when sharing or moving the notebook</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;..\df_final.csv&#39;</span><span class="p">)</span>  <span class="c1"># Load the dataset</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="caso-problema-evaluacion-del-potencial-de-energia-solar-en-barranquilla-analisis-de-irradiancia-y-variables-atmosfericas-para-la-generacion-sostenible">
<h2><strong>Caso problema: Evaluación del potencial de energía Solar en Barranquilla: Análisis de irradiancia y variables atmosféricas para la generación sostenible</strong><a class="headerlink" href="#caso-problema-evaluacion-del-potencial-de-energia-solar-en-barranquilla-analisis-de-irradiancia-y-variables-atmosfericas-para-la-generacion-sostenible" title="Permalink to this heading">#</a></h2>
<section id="contextualizacion">
<h3><strong>Contextualización</strong><a class="headerlink" href="#contextualizacion" title="Permalink to this heading">#</a></h3>
<p>El creciente interés por las fuentes de energía limpias y renovables ha generado una demanda creciente en el uso de recursos solares, tanto en entornos urbanos como en zonas costeras. <strong>Barranquilla</strong>, ubicada geográficamente en el Caribe colombiano, se beneficia de una alta exposición a la radiación solar durante la mayor parte del año, lo que representa una gran oportunidad para el desarrollo de proyectos de generación fotovoltaica.</p>
<p>Sin embargo, la capacidad de aprovechamiento de la energía solar no depende únicamente de la radiación solar incidente, sino también de varios <strong>factores atmosféricos</strong> como la temperatura, la humedad, la nubosidad, el viento y la presión, los cuales influyen directamente en la eficiencia de los sistemas solares.</p>
<p>Este trabajo presenta un <strong>análisis cuantitativo del potencial de generación solar en Barranquilla</strong>, a partir del uso de datos históricos de irradiancia difusa, índice UV y variables meteorológicas recopiladas entre los años 2020 y 2025. El objetivo es construir un <strong>modelo de regresión</strong> que permita predecir un índice compuesto denominado <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>, el cual representa una estimación del potencial energético solar considerando múltiples condiciones atmosféricas simultáneamente.</p>
<p>La modelización de este índice permitirá identificar <strong>zonas y periodos del año con mayor rendimiento potencial</strong>, sirviendo como insumo para la planificación energética, la ubicación estratégica de sistemas fotovoltaicos y el diseño de <strong>políticas públicas sostenibles</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Definition of predictor variables and target variable for regression model ===</span>

<span class="c1"># List of independent variables (features) used to estimate solar potential</span>
<span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;T2M&#39;</span><span class="p">,</span>       <span class="c1"># Temperature at 2 meters</span>
    <span class="s1">&#39;RH2M&#39;</span><span class="p">,</span>      <span class="c1"># Relative humidity at 2 meters</span>
    <span class="s1">&#39;WS10M&#39;</span><span class="p">,</span>     <span class="c1"># Wind speed at 10 meters</span>
    <span class="s1">&#39;WD10M&#39;</span><span class="p">,</span>     <span class="c1"># Wind direction at 10 meters</span>
    <span class="s1">&#39;PS&#39;</span><span class="p">,</span>        <span class="c1"># Surface pressure</span>
    <span class="s1">&#39;T2MDEW&#39;</span><span class="p">,</span>    <span class="c1"># Dew point temperature at 2 meters</span>
    <span class="s1">&#39;T2MWET&#39;</span><span class="p">,</span>    <span class="c1"># Wet bulb temperature</span>
    <span class="s1">&#39;WS50M&#39;</span>      <span class="c1"># Wind speed at 50 meters</span>
<span class="p">]</span>

<span class="c1"># Define predictor variables (X) and target variable (y)</span>
<span class="c1"># - X: DataFrame containing the selected feature columns</span>
<span class="c1"># - y: Series containing the target variable &#39;SolarIndex&#39;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">]</span>  <span class="c1"># Extract features from the dataset</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;SolarIndex&#39;</span><span class="p">]</span>  <span class="c1"># Extract the target variable</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="modelos-para-el-caso-de-regresion-y-benchmark">
<h3><strong>Modelos para el caso de regresión y Benchmark</strong><a class="headerlink" href="#modelos-para-el-caso-de-regresion-y-benchmark" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Split the dataset into training and testing sets ===</span>
<span class="c1"># - X_train, X_test: Predictor variables for training and testing</span>
<span class="c1"># - y_train, y_test: Target variable for training and testing</span>
<span class="c1"># - test_size=0.2: 20% of the data is allocated for testing</span>
<span class="c1"># - random_state=42: Ensures reproducibility of the split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Initialize a dictionary to store model results ===</span>
<span class="c1"># This dictionary will hold performance metrics for each model</span>
<span class="c1"># Metrics such as R², MSE, MAE, and training time will be stored for comparison</span>
<span class="n">model_results</span> <span class="o">=</span> <span class="p">{}</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="knn">
<h3><strong>KNN</strong><a class="headerlink" href="#knn" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === K-Nearest Neighbors (KNN) Regression ===</span>

<span class="c1"># Create a pipeline for KNN regression:</span>
<span class="c1"># - Step 1: StandardScaler for feature scaling (mean=0, variance=1)</span>
<span class="c1"># - Step 2: KNeighborsRegressor with n_neighbors=5 (default value, can be adjusted)</span>
<span class="n">knn_model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Standardize features to improve model performance</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>  <span class="c1"># KNN regression model</span>
<span class="p">])</span>

<span class="c1"># === Model Training and Timing ===</span>
<span class="c1"># Measure the time taken to train the KNN model</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the start time</span>
<span class="n">knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># Train the KNN model using the training dataset</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the end time</span>

<span class="c1"># Calculate the total training time in seconds</span>
<span class="n">knn_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Compute the elapsed training time</span>

<span class="c1"># === Prediction and Evaluation ===</span>
<span class="c1"># Predict the target variable for the test dataset</span>
<span class="c1"># - X_test: Predictor variables for testing</span>
<span class="c1"># - y_pred_knn: Predicted values for the test set</span>
<span class="n">y_pred_knn</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  <span class="c1"># Generate predictions using the trained model</span>
</pre></div>
</div>
</div>
</div>
<section id="evaluacion">
<h4><strong>Evaluación</strong><a class="headerlink" href="#evaluacion" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Store KNN Model Results ===</span>
<span class="c1"># Add the evaluation metrics for the KNN model to the `model_results` dictionary</span>
<span class="c1"># - &#39;R2&#39;: Coefficient of determination, measures the goodness of fit of the model</span>
<span class="c1"># - &#39;MSE&#39;: Mean Squared Error, measures the average squared difference between actual and predicted values</span>
<span class="c1"># - &#39;MAE&#39;: Mean Absolute Error, measures the average absolute difference between actual and predicted values</span>
<span class="c1"># - &#39;Training Time (s)&#39;: Total training time in seconds, rounded to 2 decimal places</span>
<span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;KNN&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">),</span>  <span class="c1"># Calculate R² score for the test set</span>
    <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">),</span>  <span class="c1"># Calculate Mean Squared Error</span>
    <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">),</span>  <span class="c1"># Calculate Mean Absolute Error</span>
    <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">knn_training_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Record training time rounded to 2 decimals</span>
<span class="p">}</span>

<span class="c1"># === Print KNN Model Results ===</span>
<span class="c1"># Display the evaluation metrics for the KNN model in a clear and structured format</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KNN Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;KNN&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">])</span>  <span class="c1"># Display R² score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;KNN&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">])</span>  <span class="c1"># Display Mean Squared Error</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;KNN&#39;</span><span class="p">][</span><span class="s1">&#39;MAE&#39;</span><span class="p">])</span>  <span class="c1"># Display Mean Absolute Error</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Time (s):&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;KNN&#39;</span><span class="p">][</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">])</span>  <span class="c1"># Display training time</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>KNN Results:
R2: 0.9999273186688901
MSE: 1.2585006654533117e-07
MAE: 8.691024951373174e-06
Training Time (s): 13.58
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Predicted values for the training set using the KNN model ===</span>
<span class="c1"># Generate predictions for the training set using the trained KNN model</span>
<span class="c1"># - y_train: Actual target values for the training set</span>
<span class="c1"># - y_train_pred_knn: Predicted target values for the training set</span>
<span class="n">y_train_pred_knn</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># === Plotting actual vs predicted values for the training set ===</span>
<span class="c1"># Create a scatter plot to visualize the relationship between actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred_knn</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;KNN Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Actual vs Predicted (Training Set) - KNN&#39;</span><span class="p">)</span>  <span class="c1"># Add a title to the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Values (y_train)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the x-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Values (y_train_pred)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># Add a legend to distinguish the scatter points and the ideal fit line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  <span class="c1"># Add a grid with light transparency for better visualization</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="analisis-del-modelo">
<h4><strong>Análisis del modelo</strong><a class="headerlink" href="#analisis-del-modelo" title="Permalink to this heading">#</a></h4>
<p>El modelo de regresión KNN fue entrenado sin ajuste de hiperparámetros explícito, utilizando un valor predeterminado para <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>. A pesar de su simplicidad, mostró un desempeño sobresaliente.</p>
<ul class="simple">
<li><p><strong>R²:</strong> 0.9999</p></li>
<li><p><strong>MSE:</strong> 1.26e-07</p></li>
<li><p><strong>MAE:</strong> 8.69e-06</p></li>
<li><p><strong>Tiempo de entrenamiento:</strong> 3.8 segundos</p></li>
</ul>
<section id="interpretacion-de-resultados-numericos">
<h5><strong>Interpretación de Resultados Numéricos</strong><a class="headerlink" href="#interpretacion-de-resultados-numericos" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p><strong>R² (0.9999)</strong> indica que el modelo explica <strong>más del 99.99% de la variabilidad</strong> del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>, lo que sugiere un ajuste casi perfecto en los datos de entrenamiento.</p></li>
<li><p><strong>MSE y MAE extremadamente bajos</strong>, lo cual implica que el error promedio entre las predicciones y los valores reales es prácticamente insignificante.</p></li>
<li><p><strong>Tiempo de entrenamiento razonablemente bajo</strong>, lo que hace que KNN sea competitivo incluso sin ser el más rápido.</p></li>
</ul>
</section>
<section id="analisis-visual-actual-vs-predicted">
<h5><strong>Análisis Visual (Actual vs Predicted)</strong><a class="headerlink" href="#analisis-visual-actual-vs-predicted" title="Permalink to this heading">#</a></h5>
<p>La gráfica muestra los puntos de predicción <strong>alineados casi perfectamente sobre la línea ideal (roja discontinua)</strong>. Esto indica que:</p>
<ul class="simple">
<li><p>Las predicciones son <strong>altamente precisas</strong> y siguen de cerca los valores reales.</p></li>
<li><p>No hay evidencia de dispersión, subestimación ni sobreajuste visible en los datos de entrenamiento.</p></li>
</ul>
</section>
<section id="conclusion">
<h5><strong>Conclusión</strong><a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h5>
<p>KNN demostró ser <strong>uno de los modelos más precisos</strong>, aunque este rendimiento excepcional podría deberse a <strong>overfitting en los datos de entrenamiento</strong>. Dado que KNN memoriza los datos sin generar una función explícita, su generalización debe ser validada cuidadosamente en datos no vistos. A pesar de esto, el modelo es:</p>
<ul class="simple">
<li><p><strong>Altamente preciso</strong>, ideal como benchmark de referencia.</p></li>
<li><p><strong>Sensible a ruido y a la dimensionalidad</strong>, por lo que podría beneficiarse de técnicas de reducción de dimensiones o validación cruzada.</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="lineal-regression">
<h3><strong>Lineal Regression</strong><a class="headerlink" href="#lineal-regression" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Linear Regression Model ===</span>

<span class="c1"># Create a pipeline for Linear Regression:</span>
<span class="c1"># - Step 1: StandardScaler for feature scaling (mean=0, variance=1)</span>
<span class="c1"># - Step 2: LinearRegression as the regression model</span>
<span class="n">linear_model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Standardization</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>  <span class="c1"># Linear regression model</span>
<span class="p">])</span>

<span class="c1"># === Model Training and Timing ===</span>

<span class="c1"># Start the timer to measure training time</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the start time</span>

<span class="c1"># Train the Linear Regression model using the training dataset</span>
<span class="c1"># - X_train: Predictor variables for training</span>
<span class="c1"># - y_train: Target variable for training</span>
<span class="n">linear_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Stop the timer after training is complete</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the end time</span>

<span class="c1"># === Prediction and Evaluation ===</span>

<span class="c1"># Predict the target variable for the test dataset</span>
<span class="c1"># - X_test: Predictor variables for testing</span>
<span class="c1"># - y_pred_linear: Predicted values for the test set</span>
<span class="n">y_pred_linear</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate the total training time in seconds</span>
<span class="n">linear_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Compute the elapsed training time</span>
</pre></div>
</div>
</div>
</div>
<section id="evalucion">
<h4><strong>Evalución</strong><a class="headerlink" href="#evalucion" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Store Linear Regression Results ===</span>
<span class="c1"># Add the evaluation metrics for the Linear Regression model to the `model_results` dictionary</span>
<span class="c1"># - &#39;R2&#39;: Coefficient of determination, measures the goodness of fit of the model</span>
<span class="c1"># - &#39;MSE&#39;: Mean Squared Error, measures the average squared difference between actual and predicted values</span>
<span class="c1"># - &#39;MAE&#39;: Mean Absolute Error, measures the average absolute difference between actual and predicted values</span>
<span class="c1"># - &#39;Training Time (s)&#39;: Total training time in seconds, rounded to 2 decimal places</span>
<span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Linear Regression&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear</span><span class="p">),</span>  <span class="c1"># Calculate R² score for the test set</span>
    <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear</span><span class="p">),</span>  <span class="c1"># Calculate Mean Squared Error</span>
    <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear</span><span class="p">),</span>  <span class="c1"># Calculate Mean Absolute Error</span>
    <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">linear_training_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Record training time rounded to 2 decimals</span>
<span class="p">}</span>

<span class="c1"># === Print Linear Regression Results ===</span>
<span class="c1"># Display the evaluation metrics for the Linear Regression model in a clear and structured format</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Linear Regression Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Linear Regression&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">])</span>  <span class="c1"># Display R² score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Linear Regression&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">])</span>  <span class="c1"># Display Mean Squared Error</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Linear Regression&#39;</span><span class="p">][</span><span class="s1">&#39;MAE&#39;</span><span class="p">])</span>  <span class="c1"># Display Mean Absolute Error</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Time (s):&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Linear Regression&#39;</span><span class="p">][</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">])</span>  <span class="c1"># Display training time</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Linear Regression Results:
R2: 0.25551271137630516
MSE: 0.0012891037269770042
MAE: 0.022109450944480396
Training Time (s): 0.36
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Predicted values for the training set using the Linear Regression model ===</span>
<span class="c1"># Generate predictions for the training set using the trained Linear Regression model</span>
<span class="n">y_train_pred_linear</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># === Plotting actual vs predicted values for the training set ===</span>
<span class="c1"># Create a scatter plot to visualize the relationship between actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred_linear</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Linear Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Actual vs Predicted (Training Set) - Linear Regression&#39;</span><span class="p">)</span>  <span class="c1"># Add a title to the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Values (y_train)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the x-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Values (y_train_pred)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># Add a legend to distinguish the scatter points and the ideal fit line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  <span class="c1"># Add a grid with light transparency for better visualization</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/13d97e3055a407e17e5818d26ad2d4a09efa78ddaf6cdbbdbb1fce2d069a8f6d.png" src="../_images/13d97e3055a407e17e5818d26ad2d4a09efa78ddaf6cdbbdbb1fce2d069a8f6d.png" />
</div>
</div>
</section>
<section id="id1">
<h4><strong>Análisis del modelo</strong><a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h4>
<p>El modelo de regresión lineal fue entrenado sin regularización y evaluado utilizando el conjunto de prueba. Sus métricas de desempeño son las siguientes:</p>
<ul class="simple">
<li><p><strong>R²:</strong> 0.2555</p></li>
<li><p><strong>MSE:</strong> 0.00129</p></li>
<li><p><strong>MAE:</strong> 0.0221</p></li>
<li><p><strong>Tiempo de entrenamiento:</strong> 0.36 segundos</p></li>
</ul>
<section id="id2">
<h5><strong>Interpretación de Resultados Numéricos</strong><a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p><strong>R² (0.2555)</strong> indica que el modelo explica aproximadamente el <strong>25.5% de la variabilidad</strong> del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>, exactamente igual al modelo Ridge con regularización, lo cual es consistente dado que Ridge con un alpha bajo se comporta como una regresión lineal estándar.</p></li>
<li><p><strong>MSE (0.00129)</strong> y <strong>MAE (0.0221)</strong> muestran errores bajos, pero comparables a otros modelos de baja complejidad, lo que sugiere <strong>limitaciones para capturar relaciones no lineales complejas</strong>.</p></li>
<li><p>El <strong>tiempo de entrenamiento</strong> fue extremadamente eficiente (<strong>0.36 segundos</strong>), destacando la simplicidad computacional del modelo.</p></li>
</ul>
</section>
<section id="id3">
<h5><strong>Análisis Visual (Actual vs Predicted)</strong><a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h5>
<p>La gráfica <code class="docutils literal notranslate"><span class="pre">Actual</span> <span class="pre">vs</span> <span class="pre">Predicted</span></code> muestra un patrón disperso, con predicciones azules concentradas cerca de un rango estrecho, por debajo de la línea de ajuste ideal (roja discontinua). Esto revela que:</p>
<ul class="simple">
<li><p>El modelo <strong>no logra capturar la varianza real</strong> de los datos en los extremos del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>.</p></li>
<li><p>Tiende a <strong>subestimar los valores altos</strong> y <strong>sobreestimar los bajos</strong>, indicando una falta de capacidad para adaptarse a complejidades no lineales en los datos.</p></li>
</ul>
</section>
<section id="id4">
<h5><strong>Conclusión</strong><a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>La regresión lineal es útil como <strong>modelo base simple</strong>, rápido de ejecutar y fácil de interpretar.</p></li>
<li><p>Sin embargo, su bajo R² y la forma de la gráfica de predicciones sugieren que no es adecuado para capturar <strong>patrones no lineales o interacciones complejas</strong> en los datos.</p></li>
<li><p><strong>Modelos más avanzados como XGBoost o Random Forest</strong> deben considerarse si se desea mejorar significativamente el desempeño predictivo.</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="svm-regressor">
<h3><strong>SVM Regressor</strong><a class="headerlink" href="#svm-regressor" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Support Vector Regression (SVR) ===</span>

<span class="c1"># Create a pipeline that includes:</span>
<span class="c1"># - StandardScaler: Standardizes the predictor variables to have mean=0 and variance=1</span>
<span class="c1"># - SVR: Support Vector Regression model with RBF kernel (default kernel, can be changed if needed)</span>
<span class="n">svm_model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Step 1: Feature scaling for normalization</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">))</span>  <span class="c1"># Step 2: SVR model with RBF kernel</span>
<span class="p">])</span>

<span class="c1"># === Model Training and Timing ===</span>

<span class="c1"># Start the timer to measure training time</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the start time</span>

<span class="c1"># Train the SVR model using the training dataset</span>
<span class="c1"># - X_train: Predictor variables for training</span>
<span class="c1"># - y_train: Target variable for training</span>
<span class="n">svm_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Stop the timer after training is complete</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the end time</span>

<span class="c1"># Predict the target variable for the test dataset</span>
<span class="c1"># - X_test: Predictor variables for testing</span>
<span class="c1"># - y_pred_svm: Predicted values for the test set</span>
<span class="n">y_pred_svm</span> <span class="o">=</span> <span class="n">svm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate the total training time in seconds</span>
<span class="n">svm_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Compute the elapsed training time</span>
</pre></div>
</div>
</div>
</div>
<section id="id5">
<h4><strong>Evalución</strong><a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Store SVR Model Results ===</span>
<span class="c1"># Add the evaluation metrics for the SVR model to the `model_results` dictionary</span>
<span class="c1"># - &#39;R2&#39;: Coefficient of determination, measures the goodness of fit of the model</span>
<span class="c1"># - &#39;MSE&#39;: Mean Squared Error, measures the average squared difference between actual and predicted values</span>
<span class="c1"># - &#39;MAE&#39;: Mean Absolute Error, measures the average absolute difference between actual and predicted values</span>
<span class="c1"># - &#39;Training Time (s)&#39;: Total training time in seconds, rounded to 2 decimal places</span>
<span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;SVR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svm</span><span class="p">),</span>  <span class="c1"># Calculate R² score for the test set</span>
    <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svm</span><span class="p">),</span>  <span class="c1"># Calculate Mean Squared Error</span>
    <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svm</span><span class="p">),</span>  <span class="c1"># Calculate Mean Absolute Error</span>
    <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">svm_training_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Record training time rounded to 2 decimals</span>
<span class="p">}</span>

<span class="c1"># === Print SVR Model Results ===</span>
<span class="c1"># Display the evaluation metrics for the SVR model in a clear and structured format</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">SVR Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2:&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;SVR&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">])</span>  <span class="c1"># Display R² score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;SVR&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">])</span>  <span class="c1"># Display Mean Squared Error</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;SVR&#39;</span><span class="p">][</span><span class="s1">&#39;MAE&#39;</span><span class="p">])</span>  <span class="c1"># Display Mean Absolute Error</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Time (s):&quot;</span><span class="p">,</span> <span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;SVR&#39;</span><span class="p">][</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">])</span>  <span class="c1"># Display training time</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Predicted values for the training set using the SVR model ===</span>
<span class="c1"># Generate predictions for the training set using the trained SVR model</span>
<span class="n">y_train_pred_svm</span> <span class="o">=</span> <span class="n">svm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># === Plotting actual vs predicted values for the training set ===</span>
<span class="c1"># Create a scatter plot to visualize the relationship between actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred_svm</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;SVR Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Actual vs Predicted (Training Set) - SVR&#39;</span><span class="p">)</span>  <span class="c1"># Add a title to the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Values (y_train)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the x-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Values (y_train_pred)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># Add a legend to distinguish the scatter points and the ideal fit line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  <span class="c1"># Add a grid with light transparency for better visualization</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h4><strong>Análisis del modelo</strong><a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h4>
</section>
</section>
<section id="ridge-regression">
<h3><strong>Ridge Regression</strong><a class="headerlink" href="#ridge-regression" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Ridge Regression Pipeline Configuration ===</span>

<span class="c1"># Create a pipeline that includes:</span>
<span class="c1"># - StandardScaler: Standardizes the predictor variables to have mean=0 and variance=1</span>
<span class="c1"># - Ridge: Ridge regression model for regularized linear regression</span>
<span class="n">ridge_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Step 1: Feature scaling for normalization</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">())</span>  <span class="c1"># Step 2: Ridge regression model</span>
<span class="p">])</span>

<span class="c1"># Define the hyperparameter grid for alpha (regularization strength)</span>
<span class="n">ridge_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>  <span class="c1"># Range of alpha values to test</span>

<span class="c1"># Use GridSearchCV for hyperparameter tuning with 5-fold cross-validation</span>
<span class="n">ridge_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">ridge_pipe</span><span class="p">,</span> <span class="n">ridge_params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># Optimize alpha using cross-validation</span>

<span class="c1"># === Model Training and Timing ===</span>

<span class="c1"># Start the timer to measure training time</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the start time</span>

<span class="c1"># Train the Ridge regression model using the training data</span>
<span class="n">ridge_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># Fit the model and perform hyperparameter search</span>

<span class="c1"># Stop the timer after training is complete</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the end time</span>

<span class="c1"># Predict the target variable for the test dataset</span>
<span class="n">y_pred_ridge</span> <span class="o">=</span> <span class="n">ridge_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  <span class="c1"># Generate predictions on the test set</span>

<span class="c1"># Calculate the total training time</span>
<span class="n">ridge_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Compute the elapsed training time in seconds</span>
</pre></div>
</div>
</div>
</div>
<section id="id7">
<h4><strong>Evalución</strong><a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Model Evaluation and Results Storage ===</span>

<span class="c1"># Store key performance metrics for the Ridge model:</span>
<span class="c1"># - &#39;Best Alpha&#39;: The best alpha value found during grid search</span>
<span class="c1"># - &#39;R2&#39;: Coefficient of determination, measures the goodness of fit of the model</span>
<span class="c1"># - &#39;MSE&#39;: Mean Squared Error, measures the average squared difference between actual and predicted values</span>
<span class="c1"># - &#39;MAE&#39;: Mean Absolute Error, measures the average absolute difference between actual and predicted values</span>
<span class="c1"># - &#39;Training Time (s)&#39;: Total training time in seconds, rounded to 2 decimal places</span>
<span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Best Alpha&#39;</span><span class="p">:</span> <span class="n">ridge_grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">],</span>  <span class="c1"># Best hyperparameter alpha</span>
    <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">),</span>  <span class="c1"># Coefficient of determination</span>
    <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">),</span>  <span class="c1"># Mean Squared Error</span>
    <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">),</span>  <span class="c1"># Mean Absolute Error</span>
    <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">ridge_training_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Training time rounded to 2 decimals</span>
<span class="p">}</span>

<span class="c1"># Print the Ridge model results in a clear and structured format</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ridge Regression Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best Alpha: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge&#39;</span><span class="p">][</span><span class="s1">&#39;Best Alpha&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Best alpha value</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R²: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Coefficient of determination</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Mean Squared Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge&#39;</span><span class="p">][</span><span class="s1">&#39;MAE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Mean Absolute Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Time: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge&#39;</span><span class="p">][</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>  <span class="c1"># Training time</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ridge Regression Results:
Best Alpha: 10
R²: 0.2555147596091165
MSE: 0.0012891001803958992
MAE: 0.022108922788286807
Training Time: 5.76 seconds
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Predicted values for the training set using the Ridge model ===</span>
<span class="c1"># Use the trained Ridge model (ridge_grid) to predict the target variable for the training set</span>
<span class="n">y_train_pred_ridge</span> <span class="o">=</span> <span class="n">ridge_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># === Plotting actual vs predicted values for the training set ===</span>
<span class="c1"># Create a scatter plot to visualize the relationship between actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred_ridge</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ridge Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Actual vs Predicted (Training Set)&#39;</span><span class="p">)</span>  <span class="c1"># Add a title to the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Values (y_train)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the x-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Values (y_train_pred)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># Add a legend to distinguish the scatter points and the ideal fit line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  <span class="c1"># Add a grid with light transparency for better visualization</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fef9003f8d68bd25090bbb938837010bdd14f1c2188f101f810af38ee85fc2f8.png" src="../_images/fef9003f8d68bd25090bbb938837010bdd14f1c2188f101f810af38ee85fc2f8.png" />
</div>
</div>
</section>
<section id="id8">
<h4><strong>Análisis del modelo</strong><a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h4>
<p>El modelo de regresión Ridge fue ajustado utilizando una búsqueda en grilla para encontrar el valor óptimo del hiperparámetro <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. En este caso, el mejor valor fue:</p>
<ul class="simple">
<li><p><strong>Best Alpha:</strong> 10</p></li>
<li><p><strong>R²:</strong> 0.2555</p></li>
<li><p><strong>MSE:</strong> 0.00129</p></li>
<li><p><strong>MAE:</strong> 0.0221</p></li>
<li><p><strong>Tiempo de entrenamiento:</strong> 5.76 segundos</p></li>
</ul>
<section id="id9">
<h5><strong>Interpretación de Resultados Numéricos</strong><a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p><strong>R² (0.255)</strong> indica que el modelo explica aproximadamente el <strong>25.5% de la variabilidad</strong> del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code> en los datos de prueba. Aunque esto no es muy alto, sí sugiere que el modelo ha logrado capturar parte de la relación entre las variables independientes y la variable objetivo.</p></li>
<li><p><strong>MSE (0.00129)</strong> y <strong>MAE (0.0221)</strong> son relativamente bajos, lo que indica que los errores absolutos y cuadrados promedio en las predicciones son pequeños. Sin embargo, el bajo R² sugiere que el modelo <strong>puede estar limitado en su capacidad explicativa</strong>, aunque haga buenas predicciones cerca del valor promedio.</p></li>
<li><p><strong>Tiempo de entrenamiento</strong> eficiente: Ridge es un modelo rápido y estable, ideal como línea base.</p></li>
</ul>
</section>
<section id="id10">
<h5><strong>Análisis Visual (Actual vs Predicted)</strong><a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h5>
<p>La gráfica muestra una nube de puntos azules (predicciones vs valores reales) concentrados cerca del eje horizontal, muy por debajo de la línea de ajuste ideal (roja discontinua). Esto indica que:</p>
<ul class="simple">
<li><p>El modelo <strong>tiende a subestimar</strong> las predicciones para valores más altos del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>.</p></li>
<li><p>La dispersión de los puntos indica que <strong>el modelo no se ajusta bien a la varianza real del conjunto de entrenamiento</strong>, especialmente en los extremos.</p></li>
</ul>
</section>
<section id="id11">
<h5><strong>Conclusión</strong><a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h5>
<p>Aunque Ridge ofrece <strong>estabilidad y baja varianza</strong>, su capacidad para modelar relaciones no lineales es limitada. La baja R² combinada con predicciones agrupadas sugiere que:</p>
<ul class="simple">
<li><p>El problema <strong>podría requerir un modelo más complejo o no lineal</strong>, como Random Forest o XGBoost.</p></li>
<li><p>También sería útil realizar una <strong>transformación</strong> de la variable objetivo o incluir <strong>nuevas variables</strong> si hay más disponibles.</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="lasso-regression">
<h3><strong>Lasso Regression</strong><a class="headerlink" href="#lasso-regression" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Configuration of the pipeline for Lasso Regression ===</span>

<span class="c1"># Create a pipeline that includes:</span>
<span class="c1"># - StandardScaler: Standardizes the predictor variables to have mean=0 and variance=1</span>
<span class="c1"># - Lasso: Lasso regression model for regularized linear regression</span>
<span class="n">lasso_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Step 1: Feature scaling for normalization</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">))</span>  <span class="c1"># Step 2: Lasso regression model with increased max iterations</span>
<span class="p">])</span>

<span class="c1"># Define the hyperparameter grid for alpha (regularization strength)</span>
<span class="n">lasso_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>  <span class="c1"># Range of alpha values to test</span>

<span class="c1"># Use GridSearchCV for hyperparameter tuning with 5-fold cross-validation</span>
<span class="n">lasso_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lasso_pipe</span><span class="p">,</span> <span class="n">lasso_params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># Optimize alpha using cross-validation</span>

<span class="c1"># === Model Training and Timing ===</span>

<span class="c1"># Start the timer to measure training time</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the start time</span>

<span class="c1"># Train the Lasso regression model using the training data</span>
<span class="n">lasso_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># Fit the model and perform hyperparameter search</span>

<span class="c1"># Stop the timer after training is complete</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the end time</span>

<span class="c1"># Predict the target variable for the test dataset</span>
<span class="n">y_pred_lasso</span> <span class="o">=</span> <span class="n">lasso_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  <span class="c1"># Generate predictions on the test set</span>

<span class="c1"># Calculate the total training time</span>
<span class="n">lasso_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Compute the elapsed training time in seconds</span>
</pre></div>
</div>
</div>
</div>
<section id="id12">
<h4><strong>Evalución</strong><a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Model Evaluation and Results Storage ===</span>

<span class="c1"># Store key performance metrics for the Lasso model:</span>
<span class="c1"># - &#39;Best Alpha&#39;: The best alpha value found during grid search</span>
<span class="c1"># - &#39;R2&#39;: Coefficient of determination, measures the goodness of fit of the model</span>
<span class="c1"># - &#39;MSE&#39;: Mean Squared Error, measures the average squared difference between actual and predicted values</span>
<span class="c1"># - &#39;MAE&#39;: Mean Absolute Error, measures the average absolute difference between actual and predicted values</span>
<span class="c1"># - &#39;Training Time (s)&#39;: Total training time in seconds, rounded to 2 decimal places</span>
<span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Best Alpha&#39;</span><span class="p">:</span> <span class="n">lasso_grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">],</span>  <span class="c1"># Best hyperparameter alpha</span>
    <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">),</span>  <span class="c1"># Coefficient of determination</span>
    <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">),</span>  <span class="c1"># Mean Squared Error</span>
    <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">),</span>  <span class="c1"># Mean Absolute Error</span>
    <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">lasso_training_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Training time rounded to 2 decimals</span>
<span class="p">}</span>

<span class="c1"># Print the Lasso model results in a clear and structured format</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Lasso Regression Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best Alpha: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso&#39;</span><span class="p">][</span><span class="s1">&#39;Best Alpha&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Best alpha value</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R²: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Coefficient of determination</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Mean Squared Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso&#39;</span><span class="p">][</span><span class="s1">&#39;MAE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Mean Absolute Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Time: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso&#39;</span><span class="p">][</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>  <span class="c1"># Training time</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Lasso Regression Results:
Best Alpha: 0.01
R²: 0.09657400853221798
MSE: 0.0015643112118166353
MAE: 0.019309069278737382
Training Time: 5.15 seconds
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Prediction on the training set using the Lasso model ===</span>

<span class="c1"># Use the trained Lasso model (lasso_grid) to predict the target variable for the training set</span>
<span class="n">y_train_pred_lasso</span> <span class="o">=</span> <span class="n">lasso_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># === Visualization: Actual vs Predicted Values (Training Set) ===</span>

<span class="c1"># Create a scatter plot to compare actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred_lasso</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Lasso Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Actual vs Predicted (Training Set)&#39;</span><span class="p">)</span>  <span class="c1"># Add a title to the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Values (y_train)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the x-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Values (y_train_pred)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># Add a legend to distinguish the scatter points and the ideal fit line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  <span class="c1"># Add a grid with light transparency for better visualization</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/85d131a5c03bd7160c4675c19e83bc503530e4da8a479a7ae7e44b5258bac374.png" src="../_images/85d131a5c03bd7160c4675c19e83bc503530e4da8a479a7ae7e44b5258bac374.png" />
</div>
</div>
</section>
<section id="id13">
<h4><strong>Análisis del modelo</strong><a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h4>
<p>El modelo de regresión Lasso fue ajustado utilizando validación cruzada para encontrar el valor óptimo de <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, resultando en:</p>
<ul class="simple">
<li><p><strong>Best Alpha:</strong> 0.01</p></li>
<li><p><strong>R²:</strong> 0.0966</p></li>
<li><p><strong>MSE:</strong> 0.00156</p></li>
<li><p><strong>MAE:</strong> 0.0193</p></li>
<li><p><strong>Tiempo de entrenamiento:</strong> 5.15 segundos</p></li>
</ul>
<section id="id14">
<h5><strong>Interpretación de Resultados Numéricos</strong><a class="headerlink" href="#id14" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El valor de <strong>R² (0.0966)</strong> indica que el modelo sólo explica el <strong>9.6% de la variabilidad</strong> del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>, lo cual es <strong>bajo</strong> y muestra que el ajuste general es pobre.</p></li>
<li><p>Aunque <strong>MAE (0.0193)</strong> y <strong>MSE (0.00156)</strong> son relativamente bajos, estos errores pequeños se deben en parte a que el modelo está prediciendo valores <strong>cercanos al promedio</strong>, sin capturar la variabilidad real de los datos.</p></li>
<li><p><strong>Tiempo de entrenamiento</strong> corto, lo que confirma que Lasso es un modelo eficiente computacionalmente.</p></li>
</ul>
</section>
<section id="id15">
<h5><strong>Análisis Visual (Actual vs Predicted)</strong><a class="headerlink" href="#id15" title="Permalink to this heading">#</a></h5>
<p>En la gráfica, las predicciones del modelo (puntos verdes) están fuertemente agrupadas en la parte inferior del gráfico, muy por debajo de la línea de ajuste ideal (roja punteada), lo que indica que:</p>
<ul class="simple">
<li><p>El modelo <strong>subestima sistemáticamente</strong> los valores reales.</p></li>
<li><p>Tiene una <strong>capacidad explicativa limitada</strong>, especialmente para valores altos del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>.</p></li>
</ul>
</section>
<section id="id16">
<h5><strong>Conclusión</strong><a class="headerlink" href="#id16" title="Permalink to this heading">#</a></h5>
<p>Lasso Regression, al incluir una penalización que puede reducir algunos coeficientes a cero, <strong>puede haber eliminado variables útiles</strong> para la predicción del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>. Esto puede explicar su bajo rendimiento en este caso específico.</p>
<ul class="simple">
<li><p>Puede ser útil para <strong>selección de variables</strong>, pero <strong>no se recomienda como modelo final</strong> para este problema de regresión si el objetivo es precisión predictiva.</p></li>
<li><p>Se sugiere continuar con modelos no lineales como <strong>Random Forest</strong> o <strong>XGBoost</strong>, que son más capaces de capturar interacciones complejas.</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="random-forest">
<h3><strong>Random Forest</strong><a class="headerlink" href="#random-forest" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Optimal Number of Trees (n_estimators) Search ===</span>

<span class="c1"># Base Random Forest model without hyperparameter tuning</span>
<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Define the range of values for the number of trees to test</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>  <span class="c1"># Different values for n_estimators</span>
<span class="p">}</span>

<span class="c1"># Configure GridSearchCV for hyperparameter tuning</span>
<span class="c1"># - cv=5: 5-fold cross-validation</span>
<span class="c1"># - scoring=&#39;r2&#39;: Use R² as the evaluation metric</span>
<span class="c1"># - n_jobs=-1: Use all available CPU cores for parallel processing</span>
<span class="n">grid_rf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Fit the model to the training data and perform hyperparameter search</span>
<span class="n">grid_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Print the best number of trees (n_estimators) and the corresponding R² score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best number of trees:&quot;</span><span class="p">,</span> <span class="n">grid_rf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">])</span>  <span class="c1"># Optimal n_estimators</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best R² from cross-validation:&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">grid_rf</span><span class="o">.</span><span class="n">best_score_</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>  <span class="c1"># Best R² score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best number of trees: 300
Best R² from cross-validation: 1.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Training the Random Forest model with the optimal number of trees ===</span>

<span class="c1"># Retrieve the best number of trees (n_estimators) identified by GridSearchCV</span>
<span class="n">best_n_estimators</span> <span class="o">=</span> <span class="n">grid_rf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">]</span>

<span class="c1"># Create the final Random Forest model using the optimal number of trees</span>
<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">best_n_estimators</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Start the timer to measure training time</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Train the Random Forest model using the training dataset</span>
<span class="n">rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Stop the timer after training is complete</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Predict the target variable for the test dataset</span>
<span class="n">y_pred_rf</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate the total training time in seconds</span>
<span class="n">rf_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
</pre></div>
</div>
</div>
</div>
<section id="id17">
<h4><strong>Evalución</strong><a class="headerlink" href="#id17" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Model Evaluation and Results Storage ===</span>

<span class="c1"># Store key performance metrics for the Random Forest model:</span>
<span class="c1"># - &#39;R2&#39;: Coefficient of determination, measures the goodness of fit of the model</span>
<span class="c1"># - &#39;MSE&#39;: Mean Squared Error, measures the average squared difference between actual and predicted values</span>
<span class="c1"># - &#39;MAE&#39;: Mean Absolute Error, measures the average absolute difference between actual and predicted values</span>
<span class="c1"># - &#39;Training Time (s)&#39;: Total training time in seconds, rounded to 2 decimal places</span>
<span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">),</span>  <span class="c1"># Calculate R² score for the test set</span>
    <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">),</span>  <span class="c1"># Calculate Mean Squared Error</span>
    <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">),</span>  <span class="c1"># Calculate Mean Absolute Error</span>
    <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">rf_training_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Record training time rounded to 2 decimals</span>
<span class="p">}</span>

<span class="c1"># Print the Random Forest model results in a clear and structured format</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Random Forest Regression Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R²: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Display R² score</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Display Mean Squared Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">][</span><span class="s1">&#39;MAE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Display Mean Absolute Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Time: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">][</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>  <span class="c1"># Display training time</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest Regression Results:
R²: 0.9999988603886977
MSE: 1.973273687340004e-09
MAE: 7.981250684030998e-06
Training Time: 1910.67 seconds
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Prediction on the training set using the Random Forest model ===</span>

<span class="c1"># Use the trained Random Forest model to predict the target variable for the training set</span>
<span class="n">y_train_pred_rf</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># === Visualization: Actual vs Predicted Values (Training Set) ===</span>

<span class="c1"># Create a scatter plot to compare actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred_rf</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Random Forest Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Actual vs Predicted (Training Set)&#39;</span><span class="p">)</span>  <span class="c1"># Add a title to the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Values (y_train)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the x-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Values (y_train_pred)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># Add a legend to distinguish the scatter points and the ideal fit line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  <span class="c1"># Add a grid with light transparency for better visualization</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/91c08eb7d2be6884e24efcaecd82add036998b0488b07bee56ed95d95af9d5a1.png" src="../_images/91c08eb7d2be6884e24efcaecd82add036998b0488b07bee56ed95d95af9d5a1.png" />
</div>
</div>
</section>
<section id="id18">
<h4><strong>Análisis del modelo</strong><a class="headerlink" href="#id18" title="Permalink to this heading">#</a></h4>
<p>El modelo de Random Forest fue optimizado utilizando una búsqueda en grilla (<code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>), obteniendo el mejor número de árboles (<code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>) para maximizar el rendimiento:</p>
<ul class="simple">
<li><p><strong>Mejor número de árboles:</strong> 300</p></li>
<li><p><strong>Mejor R² en validación cruzada:</strong> 1.0</p></li>
<li><p><strong>R² en conjunto de prueba:</strong> 0.99999886</p></li>
<li><p><strong>MSE:</strong> 1.97 × 10⁻⁹</p></li>
<li><p><strong>MAE:</strong> 7.98 × 10⁻⁶</p></li>
<li><p><strong>Tiempo de entrenamiento:</strong> 1910.67 segundos (~31.8 minutos)</p></li>
</ul>
<section id="id19">
<h5><strong>Interpretación de Resultados Numéricos</strong><a class="headerlink" href="#id19" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p><strong>R² (≈1.0)</strong> indica que el modelo es <strong>extremadamente preciso</strong>, explicando prácticamente el 100% de la variabilidad del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>.</p></li>
<li><p>Tanto el <strong>MSE</strong> como el <strong>MAE</strong> son <strong>cercanos a cero</strong>, lo que refleja que las diferencias entre los valores reales y predichos son mínimas.</p></li>
<li><p><strong>Tiempo de entrenamiento</strong> considerablemente más largo que en modelos lineales, lo cual es esperado en modelos de ensamble como Random Forest con muchos árboles.</p></li>
</ul>
</section>
<section id="id20">
<h5><strong>Análisis Visual (Actual vs Predicted)</strong><a class="headerlink" href="#id20" title="Permalink to this heading">#</a></h5>
<p>La gráfica muestra que las predicciones (círculos naranjas) <strong>se superponen perfectamente sobre la línea roja punteada de ajuste ideal</strong>, lo cual confirma visualmente la alta precisión del modelo.</p>
<p>No hay dispersión aparente ni errores sistemáticos visibles: el modelo <strong>predice casi perfectamente</strong> los valores del conjunto de entrenamiento.</p>
</section>
<section id="id21">
<h5><strong>Conclusión</strong><a class="headerlink" href="#id21" title="Permalink to this heading">#</a></h5>
<p>Random Forest es <strong>el modelo con mejor rendimiento hasta el momento</strong>, pero debe evaluarse con cuidado:</p>
<ul class="simple">
<li><p>Este nivel de ajuste puede ser un indicio de <strong>sobreajuste (overfitting)</strong> si la precisión fuera muy diferente en el conjunto de prueba.</p></li>
<li><p>Se recomienda verificar el rendimiento en validación cruzada y también hacer pruebas con datos nuevos o externos si es posible.</p></li>
</ul>
<p>Este modelo es una <strong>excelente elección para la predicción de <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code></strong>, especialmente si se prioriza precisión por encima de tiempo de cómputo.</p>
</section>
</section>
</section>
<hr class="docutils" />
<section id="xgboost">
<h3><strong>XGBoost</strong><a class="headerlink" href="#xgboost" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === XGBoost Model Hyperparameter Tuning and Training ===</span>

<span class="c1"># Initialize the XGBoost model with a fixed random state for reproducibility</span>
<span class="c1"># and verbosity set to 0 to suppress unnecessary output</span>
<span class="n">xgb_model</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Define the hyperparameter grid for GridSearchCV</span>
<span class="c1"># - n_estimators: Number of trees in the ensemble</span>
<span class="c1"># - learning_rate: Step size shrinkage used in updates to prevent overfitting</span>
<span class="c1"># - max_depth: Maximum depth of a tree to control model complexity</span>
<span class="n">xgb_param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">],</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Configure GridSearchCV for hyperparameter tuning</span>
<span class="c1"># - cv=5: Perform 5-fold cross-validation</span>
<span class="c1"># - scoring=&#39;r2&#39;: Use R² as the evaluation metric</span>
<span class="c1"># - n_jobs=-1: Utilize all available CPU cores for parallel processing</span>
<span class="n">xgb_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">xgb_model</span><span class="p">,</span> <span class="n">xgb_param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Fit the model to the training data and perform hyperparameter search</span>
<span class="n">xgb_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Print the best hyperparameters found during the grid search</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best hyperparameters:&quot;</span><span class="p">,</span> <span class="n">xgb_grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>

<span class="c1"># Print the best R² score obtained during cross-validation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best R² from cross-validation:&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">xgb_grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best hyperparameters: {&#39;learning_rate&#39;: 0.1, &#39;max_depth&#39;: 7, &#39;n_estimators&#39;: 300}
Best R² from cross-validation: 0.8538
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Configuration and Training of the XGBoost Model ===</span>

<span class="c1"># Create the XGBoost model with 100 trees and a fixed random state for reproducibility</span>
<span class="c1"># - n_estimators=100: Specifies the number of trees in the ensemble</span>
<span class="c1"># - random_state=42: Ensures consistent results across runs</span>
<span class="c1"># - verbosity=0: Suppresses unnecessary output during training</span>
<span class="n">xgb_model</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Start the timer to measure training time</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the start time</span>

<span class="c1"># Train the XGBoost model using the training dataset</span>
<span class="c1"># - X_train: Predictor variables for training</span>
<span class="c1"># - y_train: Target variable for training</span>
<span class="n">xgb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Stop the timer after training is complete</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the end time</span>

<span class="c1"># Predict the target variable for the test dataset</span>
<span class="c1"># - X_test: Predictor variables for testing</span>
<span class="c1"># - y_pred_xgb: Predicted values for the test set</span>
<span class="n">y_pred_xgb</span> <span class="o">=</span> <span class="n">xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate the total training time in seconds</span>
<span class="n">xgb_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Compute the elapsed training time</span>
</pre></div>
</div>
</div>
</div>
<section id="id22">
<h4><strong>Evalución</strong><a class="headerlink" href="#id22" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Model Evaluation and Results Storage ===</span>

<span class="c1"># Store the evaluation metrics for the XGBoost model in the `model_results` dictionary</span>
<span class="c1"># - &#39;R2&#39;: Coefficient of determination, measures the goodness of fit of the model</span>
<span class="c1"># - &#39;MSE&#39;: Mean Squared Error, measures the average squared difference between actual and predicted values</span>
<span class="c1"># - &#39;MAE&#39;: Mean Absolute Error, measures the average absolute difference between actual and predicted values</span>
<span class="c1"># - &#39;Training Time (s)&#39;: Total training time in seconds, rounded to 2 decimal places</span>
<span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;XGBoost&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_xgb</span><span class="p">),</span>  <span class="c1"># Calculate R² score for the test set</span>
    <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_xgb</span><span class="p">),</span>  <span class="c1"># Calculate Mean Squared Error</span>
    <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_xgb</span><span class="p">),</span>  <span class="c1"># Calculate Mean Absolute Error</span>
    <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">xgb_training_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Record training time rounded to 2 decimals</span>
<span class="p">}</span>

<span class="c1"># Print the evaluation results for the XGBoost model in a structured format</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;XGBoost Regression Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R²: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;XGBoost&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Display R² score</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;XGBoost&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Display Mean Squared Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;XGBoost&#39;</span><span class="p">][</span><span class="s1">&#39;MAE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Display Mean Absolute Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Time: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;XGBoost&#39;</span><span class="p">][</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>  <span class="c1"># Display training time</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>XGBoost Regression Results:
R²: 0.8029276172220619
MSE: 0.00034123718027869273
MAE: 0.005863526020261907
Training Time: 2.41 seconds
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Prediction on the training set using the XGBoost model ===</span>

<span class="c1"># Use the trained XGBoost model to predict the target variable for the training set</span>
<span class="n">y_train_pred_xgb</span> <span class="o">=</span> <span class="n">xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># === Visualization: Actual vs Predicted Values (Training Set) ===</span>

<span class="c1"># Create a scatter plot to compare actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred_xgb</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;XGBoost Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Actual vs Predicted (Training Set)&#39;</span><span class="p">)</span>  <span class="c1"># Add a title to the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Values (y_train)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the x-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Values (y_train_pred)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># Add a legend to distinguish the scatter points and the ideal fit line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  <span class="c1"># Add a grid with light transparency for better visualization</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4cd66e3b9f376c154f586e8a800269eadca155be0bc92eb3c5a606587554fc49.png" src="../_images/4cd66e3b9f376c154f586e8a800269eadca155be0bc92eb3c5a606587554fc49.png" />
</div>
</div>
</section>
<section id="id23">
<h4><strong>Análisis del modelo</strong><a class="headerlink" href="#id23" title="Permalink to this heading">#</a></h4>
<p>El modelo de XGBoost fue ajustado utilizando búsqueda de hiperparámetros (<code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>), encontrando los siguientes parámetros óptimos:</p>
<ul class="simple">
<li><p><strong>Best Hyperparameters:</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: 0.1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: 7</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>: 300</p></li>
</ul>
</li>
<li><p><strong>Mejor R² en validación cruzada:</strong> 0.8538</p></li>
<li><p><strong>R² en conjunto de prueba:</strong> 0.8029</p></li>
<li><p><strong>MSE:</strong> 0.00034</p></li>
<li><p><strong>MAE:</strong> 0.00586</p></li>
<li><p><strong>Tiempo de entrenamiento:</strong> 2.41 segundos</p></li>
</ul>
</section>
<section id="id24">
<h4><strong>Interpretación de Resultados Numéricos</strong><a class="headerlink" href="#id24" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>R² (0.8029)</strong> indica que el modelo es <strong>muy bueno explicando la variabilidad del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code></strong>. Aunque no alcanza el ajuste perfecto de Random Forest, tiene una generalización más razonable.</p></li>
<li><p><strong>MSE (0.00034)</strong> y <strong>MAE (0.00586)</strong> muestran que el error de predicción es <strong>bajo y estable</strong>, especialmente comparado con modelos lineales.</p></li>
<li><p>El <strong>tiempo de entrenamiento</strong> fue notablemente más corto que en Random Forest, lo que lo hace eficiente y escalable.</p></li>
</ul>
</section>
<section id="id25">
<h4><strong>Análisis Visual (Actual vs Predicted)</strong><a class="headerlink" href="#id25" title="Permalink to this heading">#</a></h4>
<p>En la gráfica, las predicciones del modelo (<code class="docutils literal notranslate"><span class="pre">XGBoost</span> <span class="pre">Predictions</span></code>) siguen la tendencia de la línea ideal, pero con:</p>
<ul class="simple">
<li><p>Una <strong>dispersión creciente a medida que los valores reales aumentan</strong>.</p></li>
<li><p>Algunos puntos alejados de la línea, lo que indica <strong>cierta dificultad del modelo en capturar completamente los valores más altos del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code></strong>.</p></li>
</ul>
<p>Aun así, la forma general de la nube de puntos es coherente con un modelo fuerte y no hay evidencia clara de sobreajuste.</p>
<section id="id26">
<h5><strong>Conclusión</strong><a class="headerlink" href="#id26" title="Permalink to this heading">#</a></h5>
<p>XGBoost ofrece una <strong>excelente precisión</strong>, con buen equilibrio entre complejidad y capacidad de generalización:</p>
<ul class="simple">
<li><p>Se adapta bien a datos con <strong>relaciones no lineales y múltiples interacciones</strong> entre variables.</p></li>
<li><p>Aunque no tiene un R² perfecto como Random Forest, su comportamiento es <strong>más realista</strong> y <strong>menos propenso al sobreajuste</strong>.</p></li>
</ul>
<p>Es una <strong>opción recomendada como modelo final</strong> si se busca una solución robusta, rápida y explicativa.</p>
</section>
</section>
</section>
<hr class="docutils" />
<section id="resultados">
<h3><strong>Resultados</strong><a class="headerlink" href="#resultados" title="Permalink to this heading">#</a></h3>
<section id="comparacion-grafica-de-los-modelos">
<h4><strong>Comparacion grafica de los modelos</strong><a class="headerlink" href="#comparacion-grafica-de-los-modelos" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Model Results ===</span>
<span class="c1"># Dictionary containing the performance metrics for each model</span>
<span class="n">model_results</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;KNN&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.9999273186688901</span><span class="p">,</span>  <span class="c1"># Coefficient of determination (goodness of fit)</span>
        <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">1.2585e-07</span><span class="p">,</span>  <span class="c1"># Mean Squared Error</span>
        <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">8.691e-06</span><span class="p">,</span>  <span class="c1"># Mean Absolute Error</span>
        <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">3.8</span>  <span class="c1"># Training time in seconds</span>
    <span class="p">},</span>
    <span class="s1">&#39;Linear Regression&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.25551271137630516</span><span class="p">,</span>
        <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">0.0012891037269770042</span><span class="p">,</span>
        <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">0.022109450944480396</span><span class="p">,</span>
        <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">0.36</span>
    <span class="p">},</span>
    <span class="s1">&#39;Ridge&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.2555147596091165</span><span class="p">,</span>
        <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">0.0012891001803958992</span><span class="p">,</span>
        <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">0.022108922788286807</span><span class="p">,</span>
        <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">5.76</span>
    <span class="p">},</span>
    <span class="s1">&#39;Lasso&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.09657400853221798</span><span class="p">,</span>
        <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">0.0015643112118166353</span><span class="p">,</span>
        <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">0.019309069278737382</span><span class="p">,</span>
        <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">5.15</span>
    <span class="p">},</span>
    <span class="s1">&#39;Random Forest&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.9999988603886977</span><span class="p">,</span>
        <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">1.973273687340004e-09</span><span class="p">,</span>
        <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">7.981250684030998e-06</span><span class="p">,</span>
        <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">1910.67</span>
    <span class="p">},</span>
    <span class="s1">&#39;XGBoost&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.8029276172220619</span><span class="p">,</span>
        <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">0.00034123718027869273</span><span class="p">,</span>
        <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">0.005863526020261907</span><span class="p">,</span>
        <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">2.41</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Convert the dictionary to a pandas DataFrame for easier manipulation and visualization</span>
<span class="n">df_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Define the metrics to compare across models</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;R2&#39;</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">,</span> <span class="s1">&#39;MAE&#39;</span><span class="p">,</span> <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">]</span>

<span class="c1"># Loop through each metric and create a bar plot for comparison</span>
<span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">df_results</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>  <span class="c1"># Model names on the x-axis</span>
        <span class="n">y</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>  <span class="c1"># Metric values on the y-axis</span>
        <span class="n">data</span><span class="o">=</span><span class="n">df_results</span><span class="p">,</span>  <span class="c1"># Data source</span>
        <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span>  <span class="c1"># Color palette for the bars</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Comparison of Models by </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>  <span class="c1"># Add a title to the plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>  <span class="c1"># Rotate x-axis labels for better readability</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>  <span class="c1"># Add a grid for the y-axis</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>  <span class="c1"># Adjust layout to prevent overlapping elements</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\jesus\AppData\Local\Temp\ipykernel_22888\4193367954.py:51: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(
</pre></div>
</div>
<img alt="../_images/bd6b800fb0ddbc480323d88c9c9238786fb231832fb27fa53c5c6e8341e15f8c.png" src="../_images/bd6b800fb0ddbc480323d88c9c9238786fb231832fb27fa53c5c6e8341e15f8c.png" />
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\jesus\AppData\Local\Temp\ipykernel_22888\4193367954.py:51: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(
</pre></div>
</div>
<img alt="../_images/074e5c1980ccbc05c5f076c587c791480fa273e0e06f447aa334b1d78df3e67c.png" src="../_images/074e5c1980ccbc05c5f076c587c791480fa273e0e06f447aa334b1d78df3e67c.png" />
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\jesus\AppData\Local\Temp\ipykernel_22888\4193367954.py:51: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(
</pre></div>
</div>
<img alt="../_images/28756d343981f29c575af9aeb5cbea73cb7a8f3e619640ff76f5ecfafaacdc08.png" src="../_images/28756d343981f29c575af9aeb5cbea73cb7a8f3e619640ff76f5ecfafaacdc08.png" />
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\jesus\AppData\Local\Temp\ipykernel_22888\4193367954.py:51: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(
</pre></div>
</div>
<img alt="../_images/c0d84265ca74da85e1570a33f5bd7564742d40005ac99b2b2f4f282714788b1d.png" src="../_images/c0d84265ca74da85e1570a33f5bd7564742d40005ac99b2b2f4f282714788b1d.png" />
</div>
</div>
</section>
</section>
<section id="id27">
<h3><a class="headerlink" href="#id27" title="Permalink to this heading">#</a></h3>
</section>
<section id="conclusiones-finales-del-analisis-de-modelos-de-regresion">
<h3><strong>Conclusiones Finales del Análisis de Modelos de Regresión</strong><a class="headerlink" href="#conclusiones-finales-del-analisis-de-modelos-de-regresion" title="Permalink to this heading">#</a></h3>
</section>
<section id="id28">
<h3><a class="headerlink" href="#id28" title="Permalink to this heading">#</a></h3>
<p>Se evaluaron seis modelos de regresión (Ridge, Lasso, Random Forest, XGBoost, KNN y Regresión Lineal) para predecir el índice compuesto <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code>, que representa el potencial de energía solar a partir de variables atmosféricas y de irradiancia.</p>
</section>
<hr class="docutils" />
<section id="id29">
<h3><a class="headerlink" href="#id29" title="Permalink to this heading">#</a></h3>
</section>
<section id="comparacion-segun-r2-bondad-de-ajuste">
<h3>Comparación según R² (Bondad de ajuste)<a class="headerlink" href="#comparacion-segun-r2-bondad-de-ajuste" title="Permalink to this heading">#</a></h3>
</section>
<section id="id30">
<h3><a class="headerlink" href="#id30" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Random Forest</strong>: R² ≈ 1.0</p>
<ul>
<li><p>Ajuste casi perfecto, pero indica sobreajuste severo en los datos de entrenamiento.</p></li>
</ul>
</li>
<li><p><strong>KNN</strong>: R² = 0.9999</p>
<ul>
<li><p>Excelente ajuste. Aunque similar a Random Forest en entrenamiento, también puede estar sobreajustado.</p></li>
</ul>
</li>
<li><p><strong>XGBoost</strong>: R² = 0.80</p>
<ul>
<li><p>Excelente rendimiento y buena generalización con un ajuste sólido.</p></li>
</ul>
</li>
<li><p><strong>Ridge</strong> / <strong>Linear Regression</strong>: R² = 0.2555</p>
<ul>
<li><p>Poder explicativo limitado. Son buenos modelos base por su estabilidad y simplicidad.</p></li>
</ul>
</li>
<li><p><strong>Lasso</strong>: R² = 0.096</p>
<ul>
<li><p>Muy bajo rendimiento, sin capacidad predictiva destacada.</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id31">
<h3><a class="headerlink" href="#id31" title="Permalink to this heading">#</a></h3>
</section>
<section id="comparacion-segun-mse-error-cuadratico-medio">
<h3>Comparación según MSE (Error Cuadrático Medio)<a class="headerlink" href="#comparacion-segun-mse-error-cuadratico-medio" title="Permalink to this heading">#</a></h3>
</section>
<section id="id32">
<h3><a class="headerlink" href="#id32" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Random Forest</strong>: MSE ≈ 0.000000002</p>
<ul>
<li><p>Error extremadamente bajo, pero reflejo de sobreajuste.</p></li>
</ul>
</li>
<li><p><strong>KNN</strong>: MSE = 1.26e-07</p>
<ul>
<li><p>Muy bajo error, pero debe verificarse en datos no vistos para descartar overfitting.</p></li>
</ul>
</li>
<li><p><strong>XGBoost</strong>: MSE = 0.00034</p>
<ul>
<li><p>Buen ajuste con bajo error, adecuado para aplicaciones reales.</p></li>
</ul>
</li>
<li><p><strong>Ridge / Linear Regression</strong>: MSE = 0.00129</p>
<ul>
<li><p>Error aceptable pero mejorable.</p></li>
</ul>
</li>
<li><p><strong>Lasso</strong>: MSE = 0.00156</p>
<ul>
<li><p>Mayor error entre los modelos evaluados.</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id33">
<h3><a class="headerlink" href="#id33" title="Permalink to this heading">#</a></h3>
</section>
<section id="comparacion-segun-mae-error-absoluto-medio">
<h3>Comparación según MAE (Error Absoluto Medio)<a class="headerlink" href="#comparacion-segun-mae-error-absoluto-medio" title="Permalink to this heading">#</a></h3>
</section>
<section id="id34">
<h3><a class="headerlink" href="#id34" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Random Forest</strong>: MAE ≈ 0.000007</p>
<ul>
<li><p>Desempeño perfecto en entrenamiento, refuerza la sospecha de sobreajuste.</p></li>
</ul>
</li>
<li><p><strong>KNN</strong>: MAE ≈ 0.000009</p>
<ul>
<li><p>Muy bajo error, desempeño impresionante en datos de entrenamiento.</p></li>
</ul>
</li>
<li><p><strong>XGBoost</strong>: MAE = 0.00586</p>
<ul>
<li><p>Error bajo con buena capacidad de predicción.</p></li>
</ul>
</li>
<li><p><strong>Lasso</strong>: MAE = 0.0193</p>
<ul>
<li><p>Error elevado y rendimiento bajo.</p></li>
</ul>
</li>
<li><p><strong>Ridge / Linear Regression</strong>: MAE = 0.0221</p>
<ul>
<li><p>Similares a Lasso, también con limitaciones predictivas.</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id35">
<h3><a class="headerlink" href="#id35" title="Permalink to this heading">#</a></h3>
</section>
<section id="comparacion-segun-tiempo-de-entrenamiento">
<h3>Comparación según Tiempo de Entrenamiento<a class="headerlink" href="#comparacion-segun-tiempo-de-entrenamiento" title="Permalink to this heading">#</a></h3>
</section>
<section id="id36">
<h3><a class="headerlink" href="#id36" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Linear Regression</strong>: 0.36 segundos</p>
<ul>
<li><p>Extremadamente rápido, ideal para pruebas iniciales o tiempo real.</p></li>
</ul>
</li>
<li><p><strong>XGBoost</strong>: 2.41 segundos</p>
<ul>
<li><p>Muy rápido y eficiente para la precisión obtenida.</p></li>
</ul>
</li>
<li><p><strong>KNN</strong>: 3.8 segundos</p>
<ul>
<li><p>Tiempo razonable, aunque podría aumentar con datos más grandes.</p></li>
</ul>
</li>
<li><p><strong>Lasso</strong>: 5.15 segundos</p>
<ul>
<li><p>Bajo tiempo de entrenamiento, pero bajo rendimiento.</p></li>
</ul>
</li>
<li><p><strong>Ridge</strong>: 5.76 segundos</p>
<ul>
<li><p>Eficiente, pero su rendimiento es limitado.</p></li>
</ul>
</li>
<li><p><strong>Random Forest</strong>: 1910.67 segundos (~31 minutos)</p>
<ul>
<li><p>Tiempo excesivo de entrenamiento que puede dificultar su implementación práctica.</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id37">
<h3><a class="headerlink" href="#id37" title="Permalink to this heading">#</a></h3>
<section id="recomendacion-final">
<h4><strong>Recomendación Final</strong><a class="headerlink" href="#recomendacion-final" title="Permalink to this heading">#</a></h4>
</section>
</section>
<section id="id38">
<h3><a class="headerlink" href="#id38" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>XGBoost</strong> sigue siendo el modelo más balanceado y <strong>recomendado</strong>: alto rendimiento, bajo error, y eficiente en tiempo.</p></li>
<li><p><strong>KNN</strong> mostró una capacidad sobresaliente en el conjunto de entrenamiento, pero se recomienda evaluar en validación cruzada para asegurar su generalización.</p></li>
<li><p><strong>Random Forest</strong> debe ser usado con precaución debido a su claro <strong>overfitting</strong>, a menos que se apliquen técnicas de control como limitación de profundidad o número mínimo de muestras por hoja.</p></li>
<li><p><strong>Ridge y Linear Regression</strong> pueden utilizarse como modelos base por su rapidez y estabilidad, aunque su poder predictivo es limitado.</p></li>
<li><p><strong>Lasso</strong> no es recomendable en este caso por su bajo desempeño global.</p></li>
</ul>
</section>
<section id="ridge-and-lasso-regression-optimized">
<h3><strong>Ridge and Lasso Regression (optimized)</strong><a class="headerlink" href="#ridge-and-lasso-regression-optimized" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Cross-Validation Configuration ===</span>
<span class="c1"># Use RepeatedKFold for robust cross-validation</span>
<span class="c1"># - n_splits=5: 5 folds in each repetition</span>
<span class="c1"># - n_repeats=3: Repeat the cross-validation process 3 times</span>
<span class="c1"># - random_state=42: Ensures reproducibility of the splits</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">RepeatedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Polynomial Feature Transformation ===</span>
<span class="c1"># Generate polynomial features of degree 2 (quadratic terms)</span>
<span class="c1"># - include_bias=False: Exclude the bias (constant) term</span>
<span class="n">poly_features</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># === Regularization Parameter Grid ===</span>
<span class="c1"># Define a wide range of alpha values for hyperparameter tuning</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>

<span class="c1"># ========== Ridge Regression with Polynomial Features ==========</span>
<span class="c1"># Create a pipeline for Ridge regression:</span>
<span class="c1"># - Step 1: Generate polynomial features</span>
<span class="c1"># - Step 2: Standardize the features using StandardScaler</span>
<span class="c1"># - Step 3: Apply Ridge regression</span>
<span class="n">ridge_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">poly_features</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># Define the hyperparameter grid for Ridge regression</span>
<span class="n">ridge_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">:</span> <span class="n">alphas</span><span class="p">}</span>

<span class="c1"># Use GridSearchCV for hyperparameter tuning with cross-validation</span>
<span class="n">ridge_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">ridge_pipe</span><span class="p">,</span> <span class="n">ridge_params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># === Training and Timing ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Start the timer</span>
<span class="n">ridge_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># Train the model</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>    <span class="c1"># End the timer</span>

<span class="c1"># Calculate training time in seconds</span>
<span class="n">ridge_poly_training_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># === Prediction ===</span>
<span class="c1"># Predict the target variable for the test dataset using the best Ridge model</span>
<span class="n">y_pred_ridge</span> <span class="o">=</span> <span class="n">ridge_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># ========== Store Results for Ridge and Lasso with Polynomial Features ==========</span>
<span class="c1"># Store Ridge regression results in the model_results dictionary</span>
<span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge_Poly&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Best Alpha&#39;</span><span class="p">:</span> <span class="n">ridge_grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">],</span>  <span class="c1"># Best alpha value</span>
    <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">),</span>  <span class="c1"># Coefficient of determination</span>
    <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">),</span>  <span class="c1"># Mean Squared Error</span>
    <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">)</span>  <span class="c1"># Mean Absolute Error</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 15 folds for each of 12 candidates, totalling 180 fits
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ridge Regression with Polynomial Features Results:&quot;</span><span class="p">)</span>
<span class="c1"># Print the Ridge regression results in a clear and structured format</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best Alpha: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge_Poly&#39;</span><span class="p">][</span><span class="s1">&#39;Best Alpha&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Best alpha value</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R²: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge_Poly&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Coefficient of determination</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge_Poly&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Mean Squared Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Ridge_Poly&#39;</span><span class="p">][</span><span class="s1">&#39;MAE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Mean Absolute Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Time: </span><span class="si">{</span><span class="n">ridge_poly_training_time</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>  <span class="c1"># Training time</span>
<span class="c1"># === Predicted values for the training set using the Ridge model ===</span>
<span class="c1"># Use the trained Ridge model (ridge_grid) to predict the target variable for the training set</span>
<span class="n">y_train_pred_ridge</span> <span class="o">=</span> <span class="n">ridge_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># === Visualization: Actual vs Predicted Values (Training Set) ===</span>
<span class="c1"># Create a scatter plot to compare actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred_ridge</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ridge Poly Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ridge Regression with Polynomial Features Results:
Best Alpha: 0.001
R²: 0.5896590863785718
MSE: 0.0007105185127585218
MAE: 0.013128978980655057
Training Time: 99.53 seconds
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x169880ca730&gt;]
</pre></div>
</div>
<img alt="../_images/35cb7adc677422b6504227c0f3996921a97dce2de71d0afa45ee831c8d18f7ab.png" src="../_images/35cb7adc677422b6504227c0f3996921a97dce2de71d0afa45ee831c8d18f7ab.png" />
</div>
</div>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ========== Lasso Regression with Polynomial Features ==========</span>
<span class="c1"># Create a pipeline for Lasso regression:</span>
<span class="c1"># - Step 1: Generate polynomial features</span>
<span class="c1"># - Step 2: Standardize the features using StandardScaler</span>
<span class="c1"># - Step 3: Apply Lasso regression</span>
<span class="n">lasso_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">poly_features</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">))</span>  <span class="c1"># Increase max_iter to ensure convergence</span>
<span class="p">])</span>

<span class="c1"># Define the hyperparameter grid for Lasso regression</span>
<span class="n">lasso_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">:</span> <span class="n">alphas</span><span class="p">}</span>

<span class="c1"># Use GridSearchCV for hyperparameter tuning with cross-validation</span>
<span class="n">lasso_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">lasso_pipe</span><span class="p">,</span> <span class="n">lasso_params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># ========== Model Training and Timing ==========</span>
<span class="c1"># Start timer</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Train the Lasso regression model and find the best alpha</span>
<span class="n">lasso_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Stop timer</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Calculate training time</span>
<span class="n">lasso_poly_training_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># ========== Prediction ==========</span>
<span class="c1"># Predict the target variable for the test dataset using the best Lasso model</span>
<span class="n">y_pred_lasso</span> <span class="o">=</span> <span class="n">lasso_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># ========== Store Results ==========</span>
<span class="c1"># Store Lasso regression results in the model_results dictionary</span>
<span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso_Poly&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Best Alpha&#39;</span><span class="p">:</span> <span class="n">lasso_grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;model__alpha&#39;</span><span class="p">],</span>  <span class="c1"># Best alpha value</span>
    <span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">),</span>  <span class="c1"># Coefficient of determination</span>
    <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">),</span>  <span class="c1"># Mean Squared Error</span>
    <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lasso</span><span class="p">),</span>  <span class="c1"># Mean Absolute Error</span>
    <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="n">lasso_poly_training_time</span>  <span class="c1"># Time in seconds</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 15 folds for each of 12 candidates, totalling 180 fits
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Lasso Regression with Polynomial Features Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best Alpha: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso_Poly&#39;</span><span class="p">][</span><span class="s1">&#39;Best Alpha&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Best alpha value</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R²: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso_Poly&#39;</span><span class="p">][</span><span class="s1">&#39;R2&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Coefficient of determination</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso_Poly&#39;</span><span class="p">][</span><span class="s1">&#39;MSE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Mean Squared Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">model_results</span><span class="p">[</span><span class="s1">&#39;Lasso_Poly&#39;</span><span class="p">][</span><span class="s1">&#39;MAE&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Mean Absolute Error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Time: </span><span class="si">{</span><span class="n">lasso_poly_training_time</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>  <span class="c1"># Training time</span>
<span class="c1"># === Prediction on the training set using the Lasso model ===</span>
<span class="c1"># Use the trained Lasso model (lasso_grid) to predict the target variable for the training set</span>
<span class="n">y_train_pred_lasso</span> <span class="o">=</span> <span class="n">lasso_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># === Visualization: Actual vs Predicted Values (Training Set) ===</span>
<span class="c1"># Create a scatter plot to compare actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred_lasso</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Lasso Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Lasso Regression with Polynomial Features Results:
Best Alpha: 0.001
R²: 0.42159301982221686
MSE: 0.0010015303219415685
MAE: 0.017205274528923325
Training Time: 258.45 seconds
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x169881bceb0&gt;]
</pre></div>
</div>
<img alt="../_images/0dad59dbc8e8dca451fca5ba24a11e5a2ca567fae1d352c74f65c602dd01b8f2.png" src="../_images/0dad59dbc8e8dca451fca5ba24a11e5a2ca567fae1d352c74f65c602dd01b8f2.png" />
</div>
</div>
<section id="analisis-de-lasso-y-ridge-mejorados">
<h4><strong>Análisis de Lasso y Ridge mejorados:</strong><a class="headerlink" href="#analisis-de-lasso-y-ridge-mejorados" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Result dictionary from the combined results</span>
<span class="n">model_results</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Ridge&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.2555</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">0.00129</span><span class="p">,</span> <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">0.0221</span><span class="p">,</span> <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">5.76</span><span class="p">},</span>
    <span class="s1">&#39;Lasso&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.0966</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">0.00156</span><span class="p">,</span> <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">0.0193</span><span class="p">,</span> <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">5.15</span><span class="p">},</span>
    <span class="s1">&#39;Ridge_Poly&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.5897</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">0.00071</span><span class="p">,</span> <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">0.0131</span><span class="p">,</span> <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">99.53</span><span class="p">},</span>
    <span class="s1">&#39;Lasso_Poly&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;R2&#39;</span><span class="p">:</span> <span class="mf">0.4216</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="mf">0.00100</span><span class="p">,</span> <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="mf">0.0172</span><span class="p">,</span> <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">:</span> <span class="mf">258.45</span><span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Convert to DataFrame</span>
<span class="n">result_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Define metrics</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;R2&#39;</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">,</span> <span class="s1">&#39;MAE&#39;</span><span class="p">,</span> <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">]</span>  <span class="c1"># Colors for each model</span>

<span class="c1"># Plotting</span>
<span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">result_df</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Comparación de modelos según </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/205f0446e896b9a54757653fbb9fbead617308d650c1a62b4f5e736dbb0b1abc.png" src="../_images/205f0446e896b9a54757653fbb9fbead617308d650c1a62b4f5e736dbb0b1abc.png" />
<img alt="../_images/998a66abc2a8f2d8d3997f0da78db36f6c0d88d30c6fbc544d0bcafe45b2c8b5.png" src="../_images/998a66abc2a8f2d8d3997f0da78db36f6c0d88d30c6fbc544d0bcafe45b2c8b5.png" />
<img alt="../_images/f442a52f91192e9c32a61ba4cadc94f8db2c3456692159e6e13bfd440ca8cfe5.png" src="../_images/f442a52f91192e9c32a61ba4cadc94f8db2c3456692159e6e13bfd440ca8cfe5.png" />
<img alt="../_images/e71b9e6fa96047c49bb87b609670da4c6c56cf3487267c4d38c52192c2506862.png" src="../_images/e71b9e6fa96047c49bb87b609670da4c6c56cf3487267c4d38c52192c2506862.png" />
</div>
</div>
<section id="comparacion-de-modelos-lineales-antes-vs-despues-de-la-optimizacion">
<h5><strong>Comparación de Modelos Lineales: Antes vs Después de la Optimización</strong><a class="headerlink" href="#comparacion-de-modelos-lineales-antes-vs-despues-de-la-optimizacion" title="Permalink to this heading">#</a></h5>
<p>Se evaluaron las versiones extendidas de Ridge y Lasso Regression incorporando:</p>
<ul class="simple">
<li><p>Transformación polinómica (grado 2) para capturar relaciones no lineales.</p></li>
<li><p>Validación cruzada repetida (RepeatedKFold) para mayor robustez.</p></li>
<li><p>Rango más amplio de valores de α (alpha) para un ajuste fino de regularización.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="ridge-regression-optimizado">
<h5>1. Ridge Regression (Optimizado)<a class="headerlink" href="#ridge-regression-optimizado" title="Permalink to this heading">#</a></h5>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Métrica</p></th>
<th class="head"><p>Modelo Original</p></th>
<th class="head"><p>Modelo con PolynomialFeatures</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>R²</p></td>
<td><p>0.2555</p></td>
<td><p>0.5896</p></td>
</tr>
<tr class="row-odd"><td><p>MSE</p></td>
<td><p>0.00129</p></td>
<td><p>0.00071</p></td>
</tr>
<tr class="row-even"><td><p>MAE</p></td>
<td><p>0.0221</p></td>
<td><p>0.0131</p></td>
</tr>
<tr class="row-odd"><td><p>Tiempo de Entrenamiento</p></td>
<td><p>5.76 s</p></td>
<td><p>99.53 s</p></td>
</tr>
</tbody>
</table>
<p><strong>Análisis</strong>:<br />
La inclusión de términos polinómicos mejora significativamente el ajuste del modelo, reduciendo los errores y aumentando la capacidad explicativa. El tiempo de entrenamiento es mayor, pero aceptable para tareas analíticas.</p>
</section>
<hr class="docutils" />
<section id="lasso-regression-optimizado">
<h5>2. Lasso Regression (Optimizado)<a class="headerlink" href="#lasso-regression-optimizado" title="Permalink to this heading">#</a></h5>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Métrica</p></th>
<th class="head"><p>Modelo Original</p></th>
<th class="head"><p>Modelo con PolynomialFeatures</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>R²</p></td>
<td><p>0.0965</p></td>
<td><p>0.4216</p></td>
</tr>
<tr class="row-odd"><td><p>MSE</p></td>
<td><p>0.00156</p></td>
<td><p>0.00100</p></td>
</tr>
<tr class="row-even"><td><p>MAE</p></td>
<td><p>0.0193</p></td>
<td><p>0.0172</p></td>
</tr>
<tr class="row-odd"><td><p>Tiempo de Entrenamiento</p></td>
<td><p>5.15 s</p></td>
<td><p>258.45 s</p></td>
</tr>
</tbody>
</table>
<p><strong>Análisis</strong>:<br />
El modelo Lasso optimizado mejora de manera moderada, aunque con un aumento considerable en el tiempo de entrenamiento. Puede ser útil cuando se busca interpretar o seleccionar variables, pero no es el más eficiente para predicción.</p>
</section>
<hr class="docutils" />
<section id="conclusion-comparativa">
<h5>Conclusión Comparativa<a class="headerlink" href="#conclusion-comparativa" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>La incorporación de características polinómicas mejora el rendimiento de los modelos lineales.</p></li>
<li><p>Ridge con PolynomialFeatures ofrece una alternativa sólida entre precisión y eficiencia computacional.</p></li>
<li><p>XGBoost continúa siendo el modelo más robusto en términos de desempeño predictivo.</p></li>
<li><p>Se recomienda Ridge+Polynomial como modelo base interpretable, mientras que XGBoost es ideal para aplicaciones donde la precisión es crítica.</p></li>
</ul>
<p>En este análisis, <strong>no se aplicó un proceso de optimización adicional al modelo de Random Forest</strong>, ya que su entrenamiento original ya implicó una búsqueda de hiperparámetros para encontrar el mejor número de árboles (<code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>). Sin embargo, debido a su <strong>elevado costo computacional</strong> (más de 30 minutos de entrenamiento), se decidió no continuar afinando este modelo para no comprometer la eficiencia temporal del sistema.</p>
<p>Por otro lado, <strong>XGBoost fue entrenado con un conjunto de hiperparámetros optimizados</strong>, logrando un excelente equilibrio entre precisión y tiempo de entrenamiento. Debido a sus resultados sobresalientes (R² superior al 0.80 con un tiempo menor a 3 segundos), <strong>este modelo será considerado como el punto de referencia (baseline)</strong> a superar o igualar mediante modelos más simples y explicables como Ridge con características polinómicas. Esta estrategia permite balancear <strong>eficiencia, interpretabilidad y capacidad predictiva</strong> en futuras implementaciones.</p>
</section>
</section>
</section>
<section id="knn-and-regression-optimized">
<h3><strong>KNN and Regression (optimized)</strong><a class="headerlink" href="#knn-and-regression-optimized" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Parameters for GridSearchCV ===</span>
<span class="c1"># Define the hyperparameter grid for KNN:</span>
<span class="c1"># - &#39;model__n_neighbors&#39;: Number of neighbors to consider for prediction</span>
<span class="c1"># - &#39;model__weights&#39;: Weight function used in prediction (&#39;uniform&#39; or &#39;distance&#39;)</span>
<span class="c1"># - &#39;model__p&#39;: Power parameter for the Minkowski metric (1=Manhattan, 2=Euclidean)</span>
<span class="n">knn_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;model__n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
    <span class="s1">&#39;model__weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">],</span>
    <span class="s1">&#39;model__p&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># Manhattan (1) and Euclidean (2) distances</span>
<span class="p">}</span>

<span class="c1"># === Pipeline for KNN ===</span>
<span class="c1"># Create a pipeline with the following steps:</span>
<span class="c1"># - Step 1: StandardScaler to normalize the features (mean=0, variance=1)</span>
<span class="c1"># - Step 2: KNeighborsRegressor as the regression model</span>
<span class="n">knn_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Feature scaling</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">())</span>  <span class="c1"># KNN regression model</span>
<span class="p">])</span>

<span class="c1"># === GridSearchCV for Hyperparameter Optimization ===</span>
<span class="c1"># Use GridSearchCV to find the best combination of hyperparameters:</span>
<span class="c1"># - cv=5: Perform 5-fold cross-validation</span>
<span class="c1"># - scoring=&#39;r2&#39;: Use R² as the evaluation metric</span>
<span class="c1"># - n_jobs=-1: Utilize all available CPU cores for parallel processing</span>
<span class="c1"># - verbose=1: Display progress during the search</span>
<span class="n">knn_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">knn_pipe</span><span class="p">,</span> <span class="n">knn_params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># === Training and Timing ===</span>
<span class="c1"># Measure the time taken to train the KNN model with GridSearchCV</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the start time</span>
<span class="n">knn_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># Train the model and perform hyperparameter search</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Record the end time</span>

<span class="c1"># Calculate the total training time in seconds</span>
<span class="n">knn_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Compute elapsed time</span>

<span class="c1"># === Predictions and Metrics ===</span>
<span class="c1"># Generate predictions for the test dataset using the best KNN model</span>
<span class="c1"># - X_test: Predictor variables for testing</span>
<span class="c1"># - y_pred_knn_opt: Predicted values for the test set</span>
<span class="n">y_pred_knn_opt</span> <span class="o">=</span> <span class="n">knn_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  <span class="c1"># Predict using the optimized model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 20 candidates, totalling 100 fits
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;knn with the best hyperparameters found:&quot;</span><span class="p">)</span>

<span class="c1"># === Display the best hyperparameters found during GridSearchCV ===</span>


<span class="c1"># - knn_grid.best_params_: Dictionary of the best hyperparameters for the KNN model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best hyperparameters found:&quot;</span><span class="p">,</span> <span class="n">knn_grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>

<span class="c1"># === Evaluate the KNN model on the test dataset ===</span>
<span class="c1"># - R²: Coefficient of determination, measures how well the model explains the variability of the target variable</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R²:&quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn_opt</span><span class="p">))</span>

<span class="c1"># - MSE: Mean Squared Error, measures the average squared difference between actual and predicted values</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE:&quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn_opt</span><span class="p">))</span>

<span class="c1"># - MAE: Mean Absolute Error, measures the average absolute difference between actual and predicted values</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE:&quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn_opt</span><span class="p">))</span>

<span class="c1"># === Display the total training time for the KNN model ===</span>
<span class="c1"># - knn_training_time: Time taken to train the model, rounded to 2 decimal places for readability</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training time (s):&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">knn_training_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>knn with the best hyperparameters found:
Best hyperparameters found: {&#39;model__n_neighbors&#39;: 11, &#39;model__p&#39;: 1, &#39;model__weights&#39;: &#39;distance&#39;}
R²: 0.999999901049925
MSE: 1.7133524292667098e-10
MAE: 4.85113266456339e-06
Training time (s): 164.77
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Create a figure for visualization ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>

<span class="c1"># === Scatter Plot: Actual vs Predicted Values ===</span>
<span class="c1"># Plot the actual values (y_test) against the predicted values (y_pred_knn_opt)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn_opt</span><span class="p">,</span> 
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> 
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;KNN Predictions&#39;</span>  <span class="c1"># Add a label for the legend</span>
<span class="p">)</span>

<span class="c1"># === Ideal Fit Line (y = x) ===</span>
<span class="c1"># Plot a reference line to indicate the ideal fit (perfect predictions)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>  <span class="c1"># Define the range for the line</span>
    <span class="p">[</span><span class="n">y_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span> 
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> 
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit&#39;</span>  <span class="c1"># Add a label for the legend</span>
<span class="p">)</span>

<span class="c1"># === Add Titles and Labels ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Actual vs Predicted (KNN Optimized)&#39;</span><span class="p">)</span>  <span class="c1"># Add a title to the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Values (y_test)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the x-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Values (y_pred_knn_opt)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>

<span class="c1"># === Add Legend and Grid ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># Display the legend to differentiate between the scatter points and the ideal fit line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  <span class="c1"># Add a grid with light transparency for better visualization</span>

<span class="c1"># === Adjust Layout and Display ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>  <span class="c1"># Adjust the layout to prevent overlapping elements</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1bd9fdd51f55a549768435d48d827c1aac536b8ea6d5f75e12041924e63b15f7.png" src="../_images/1bd9fdd51f55a549768435d48d827c1aac536b8ea6d5f75e12041924e63b15f7.png" />
</div>
</div>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Polynomial Feature Transformation ===</span>
<span class="c1"># Generate polynomial features of degree 2 (you can try 3 también si deseas)</span>
<span class="n">poly_features</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># === Linear Regression Pipeline with Polynomial Features ===</span>
<span class="n">linear_poly_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">poly_features</span><span class="p">),</span>          <span class="c1"># Step 1: Add polynomial terms</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>     <span class="c1"># Step 2: Standardize features</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())</span>     <span class="c1"># Step 3: Linear Regression</span>
<span class="p">])</span>

<span class="c1"># === Training with Timing ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>                      <span class="c1"># Start timer</span>
<span class="n">linear_poly_pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>        <span class="c1"># Fit model</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>                        <span class="c1"># End timer</span>
<span class="n">linear_poly_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Training duration</span>

<span class="c1"># === Prediction and Evaluation ===</span>
<span class="n">y_pred_linear_poly</span> <span class="o">=</span> <span class="n">linear_poly_pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  <span class="c1"># Predict on test data</span>

<span class="c1"># Optional: Cross-validated R² for robustness</span>
<span class="n">cv_r2</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_poly_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># === Output results ===</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Time: </span><span class="si">{</span><span class="n">linear_poly_training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cross-Validated R²: </span><span class="si">{</span><span class="n">cv_r2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Time: 3.82 seconds
Cross-Validated R²: 0.5904
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Evaluate the performance of the Linear Regression model with Polynomial Features ===</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Linear Regression with Polynomial Features Results:&quot;</span><span class="p">)</span>

<span class="c1"># Print the R² score for the test dataset</span>
<span class="c1"># R² (coefficient of determination) indicates how well the model explains the variability of the target variable</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test R²: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_linear_poly</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Print the Mean Squared Error (MSE) for the test dataset</span>
<span class="c1"># MSE measures the average squared difference between actual and predicted values</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test MSE: </span><span class="si">{</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_linear_poly</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Print the Mean Absolute Error (MAE) for the test dataset</span>
<span class="c1"># MAE measures the average absolute difference between actual and predicted values</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test MAE: </span><span class="si">{</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_linear_poly</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Print the total training time for the model</span>
<span class="c1"># This helps evaluate the computational efficiency of the model</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Time: </span><span class="si">{</span><span class="n">linear_poly_training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Linear Regression with Polynomial Features Results:
Test R²: 0.5897
Test MSE: 0.0007
Test MAE: 0.0131
Training Time: 3.82 seconds
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Visualization: Actual vs Predicted Plot for Linear Regression with PolynomialFeatures ===</span>

<span class="c1"># Ensure the following variables are correctly defined:</span>
<span class="c1"># - y_test: Actual target values from the test dataset</span>
<span class="c1"># - y_pred_linear_poly: Predicted values from the trained polynomial regression model</span>

<span class="c1"># Create a scatter plot to visualize the relationship between actual and predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_linear_poly</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predictions&#39;</span>
<span class="p">)</span>  <span class="c1"># Scatter plot of actual vs predicted values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">y_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="p">[</span><span class="n">y_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ideal Fit (y = x)&#39;</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># Plot the ideal fit line (y = x) for reference</span>

<span class="c1"># Add title and axis labels for clarity</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Actual vs Predicted - Linear Regression with PolynomialFeatures&#39;</span><span class="p">)</span>  <span class="c1"># Plot title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Values (y_test)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the x-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Values (y_pred)&#39;</span><span class="p">)</span>  <span class="c1"># Label for the y-axis</span>

<span class="c1"># Add legend and grid for better visualization</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># Add a legend to distinguish the scatter points and the ideal fit line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  <span class="c1"># Add a grid with light transparency for better visualization</span>

<span class="c1"># Adjust layout to prevent overlapping elements and display the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>  <span class="c1"># Automatically adjust subplot parameters for better layout</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/bab254cb562ab701b190d805087e883a879ee71ffc830bcf5749b9b999280a07.png" src="../_images/bab254cb562ab701b190d805087e883a879ee71ffc830bcf5749b9b999280a07.png" />
</div>
</div>
<section id="analsis-de-regresion-lineal-y-knn-mejorados">
<h4><strong>Análsis de Regresion lineal y KNN mejorados</strong><a class="headerlink" href="#analsis-de-regresion-lineal-y-knn-mejorados" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Result dictionary from the combined results</span>
<span class="n">model_results</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Linear&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;R2&quot;</span><span class="p">:</span> <span class="mf">0.2555</span><span class="p">,</span> <span class="s2">&quot;MSE&quot;</span><span class="p">:</span> <span class="mf">0.00129</span><span class="p">,</span> <span class="s2">&quot;MAE&quot;</span><span class="p">:</span> <span class="mf">0.0221</span><span class="p">,</span> <span class="s2">&quot;Training Time (s)&quot;</span><span class="p">:</span> <span class="mf">0.36</span><span class="p">},</span>
    <span class="s2">&quot;Linear_Poly&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;R2&quot;</span><span class="p">:</span> <span class="mf">0.5897</span><span class="p">,</span>
        <span class="s2">&quot;MSE&quot;</span><span class="p">:</span> <span class="mf">0.0007</span><span class="p">,</span>
        <span class="s2">&quot;MAE&quot;</span><span class="p">:</span> <span class="mf">0.0131</span><span class="p">,</span>
        <span class="s2">&quot;Training Time (s)&quot;</span><span class="p">:</span> <span class="mf">3.82</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;KNN&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;R2&quot;</span><span class="p">:</span> <span class="mf">0.9999</span><span class="p">,</span> <span class="s2">&quot;MSE&quot;</span><span class="p">:</span> <span class="mf">1.26e-07</span><span class="p">,</span> <span class="s2">&quot;MAE&quot;</span><span class="p">:</span> <span class="mf">8.69e-06</span><span class="p">,</span> <span class="s2">&quot;Training Time (s)&quot;</span><span class="p">:</span> <span class="mf">3.8</span><span class="p">},</span>
    <span class="s2">&quot;KNN_Opt&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;R2&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;MSE&quot;</span><span class="p">:</span> <span class="mf">1.71e-10</span><span class="p">,</span>
        <span class="s2">&quot;MAE&quot;</span><span class="p">:</span> <span class="mf">4.85e-06</span><span class="p">,</span>
        <span class="s2">&quot;Training Time (s)&quot;</span><span class="p">:</span> <span class="mf">164.77</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="c1"># Convert to DataFrame</span>
<span class="n">result_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Define metrics and color palette</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;R2&quot;</span><span class="p">,</span> <span class="s2">&quot;MSE&quot;</span><span class="p">,</span> <span class="s2">&quot;MAE&quot;</span><span class="p">,</span> <span class="s2">&quot;Training Time (s)&quot;</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;skyblue&quot;</span><span class="p">,</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="s2">&quot;purple&quot;</span><span class="p">]</span>

<span class="c1"># Plotting</span>
<span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">result_df</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Comparación de modelos según </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ad7fccbfef12d95942e51a73c1e61e4a63e0275e17f24ad5e8a2c0691c29bf02.png" src="../_images/ad7fccbfef12d95942e51a73c1e61e4a63e0275e17f24ad5e8a2c0691c29bf02.png" />
<img alt="../_images/3c8811e34de6395de2be98fda8559b462fa245067124735925bb62bb3717bc48.png" src="../_images/3c8811e34de6395de2be98fda8559b462fa245067124735925bb62bb3717bc48.png" />
<img alt="../_images/90cdb27d149130f058156e23e140b9ff7f633c9b647049895a34523484b89e3c.png" src="../_images/90cdb27d149130f058156e23e140b9ff7f633c9b647049895a34523484b89e3c.png" />
<img alt="../_images/a61f8b6e8434f1b235567edff4454b2d38a9b1541a58b775785254b40db1588c.png" src="../_images/a61f8b6e8434f1b235567edff4454b2d38a9b1541a58b775785254b40db1588c.png" />
</div>
</div>
<section id="comparacion-de-modelos-lineal-y-knn-antes-vs-despues-de-la-optimizacion">
<h5><strong>Comparación de Modelos: Lineal y KNN - Antes vs Después de la Optimización</strong><a class="headerlink" href="#comparacion-de-modelos-lineal-y-knn-antes-vs-despues-de-la-optimizacion" title="Permalink to this heading">#</a></h5>
<p>Se aplicaron mejoras específicas a los modelos lineales y KNN para elevar su rendimiento:</p>
<ul class="simple">
<li><p>Para <strong>Linear Regression</strong>: se introdujo una transformación polinómica (grado 2).</p></li>
<li><p>Para <strong>KNN</strong>: se ajustaron los hiperparámetros mediante búsqueda en grilla (<code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>, <code class="docutils literal notranslate"><span class="pre">weights</span></code>, <code class="docutils literal notranslate"><span class="pre">p</span></code>).</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="linear-regression-con-y-sin-polynomialfeatures">
<h5>1. Linear Regression (con y sin PolynomialFeatures)<a class="headerlink" href="#linear-regression-con-y-sin-polynomialfeatures" title="Permalink to this heading">#</a></h5>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Métrica</p></th>
<th class="head"><p>Modelo Original</p></th>
<th class="head"><p>Modelo con PolynomialFeatures</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>R²</p></td>
<td><p>0.2555</p></td>
<td><p>0.5897</p></td>
</tr>
<tr class="row-odd"><td><p>MSE</p></td>
<td><p>0.00129</p></td>
<td><p>0.00070</p></td>
</tr>
<tr class="row-even"><td><p>MAE</p></td>
<td><p>0.0221</p></td>
<td><p>0.0131</p></td>
</tr>
<tr class="row-odd"><td><p>Tiempo de Entrenamiento</p></td>
<td><p>0.36 s</p></td>
<td><p>3.82 s</p></td>
</tr>
</tbody>
</table>
<p><strong>Análisis</strong>:<br />
La transformación polinómica incrementó significativamente la capacidad predictiva del modelo, más que duplicando el R². El aumento en el tiempo de entrenamiento sigue siendo aceptable. Esto sugiere que el modelo original no capturaba relaciones no lineales presentes en los datos.</p>
</section>
<hr class="docutils" />
<section id="k-nearest-neighbors-knn">
<h5>2. K-Nearest Neighbors (KNN)<a class="headerlink" href="#k-nearest-neighbors-knn" title="Permalink to this heading">#</a></h5>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Métrica</p></th>
<th class="head"><p>Modelo Original</p></th>
<th class="head"><p>Modelo Optimizado</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>R²</p></td>
<td><p>0.9999</p></td>
<td><p>0.9999999</p></td>
</tr>
<tr class="row-odd"><td><p>MSE</p></td>
<td><p>1.26e-07</p></td>
<td><p>1.71e-10</p></td>
</tr>
<tr class="row-even"><td><p>MAE</p></td>
<td><p>8.69e-06</p></td>
<td><p>4.85e-06</p></td>
</tr>
<tr class="row-odd"><td><p>Tiempo de Entrenamiento</p></td>
<td><p>3.80 s</p></td>
<td><p>164.77 s</p></td>
</tr>
</tbody>
</table>
<p><strong>Análisis</strong>:<br />
Aunque el rendimiento ya era extremadamente alto, el modelo optimizado logra una mejora marginal adicional en las métricas de error. Sin embargo, el costo computacional es notablemente mayor, con un tiempo de entrenamiento 43 veces más alto. Esto sugiere que, si bien la optimización aporta precisión, debe usarse con criterio dependiendo de la disponibilidad de recursos.</p>
</section>
<hr class="docutils" />
<section id="id39">
<h5>Conclusión Comparativa<a class="headerlink" href="#id39" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>La <strong>regresión lineal</strong> se beneficia de la transformación polinómica, especialmente en problemas donde existen relaciones cuadráticas o interacciones entre variables.</p></li>
<li><p><strong>KNN</strong>, incluso sin optimización, ofrece un rendimiento sobresaliente, aunque con posible <strong>sobreajuste</strong>. La versión optimizada mejora levemente pero con gran costo computacional.</p></li>
<li><p>Ambos modelos optimizados pueden servir como alternativas a modelos más complejos, pero el <strong>balance entre precisión y eficiencia</strong> debe guiar su elección según el contexto de uso, no obstante se concluye que la diferencia en mejora de precision <strong>no es significativa</strong>.</p></li>
</ul>
</section>
</section>
</section>
<section id="analisis-final-con-todos-los-modelos-optimizados-y-no-optimizados">
<h3><strong>Análisis final con todos los modelos optimizados y no optimizados</strong><a class="headerlink" href="#analisis-final-con-todos-los-modelos-optimizados-y-no-optimizados" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define a color palette for the models</span>
<span class="n">model_colors</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Linear&#39;</span><span class="p">:</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Ridge&#39;</span><span class="p">:</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Lasso&#39;</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Ridge_Poly&#39;</span><span class="p">:</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Lasso_Poly&#39;</span><span class="p">:</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Linear_Poly&#39;</span><span class="p">:</span> <span class="s1">&#39;cyan&#39;</span><span class="p">,</span>
    <span class="s1">&#39;KNN&#39;</span><span class="p">:</span> <span class="s1">&#39;pink&#39;</span><span class="p">,</span>
    <span class="s1">&#39;KNN_Opt&#39;</span><span class="p">:</span> <span class="s1">&#39;yellow&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Random Forest&#39;</span><span class="p">:</span> <span class="s1">&#39;brown&#39;</span><span class="p">,</span>
    <span class="s1">&#39;XGBoost&#39;</span><span class="p">:</span> <span class="s1">&#39;gray&#39;</span>
<span class="p">}</span>

<span class="c1"># Convert the dictionary to a DataFrame</span>
<span class="n">df_all_models</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Create bar plots for each metric</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;R2&#39;</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">,</span> <span class="s1">&#39;MAE&#39;</span><span class="p">,</span> <span class="s1">&#39;Training Time (s)&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">bars</span> <span class="o">=</span> <span class="n">df_all_models</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> 
        <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="n">model_colors</span><span class="p">[</span><span class="n">model</span><span class="p">]</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">df_all_models</span><span class="o">.</span><span class="n">index</span><span class="p">],</span>  <span class="c1"># Apply colors</span>
        <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Comparación de modelos por </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/913854a3f3703074c0e2606c9835c70dbea73ad28b16e9a43cd89715fae5436a.png" src="../_images/913854a3f3703074c0e2606c9835c70dbea73ad28b16e9a43cd89715fae5436a.png" />
<img alt="../_images/4ef2bbfa566f97815cd5941d4e18d88541ce80fe37f6601c5f5752b750fdb01a.png" src="../_images/4ef2bbfa566f97815cd5941d4e18d88541ce80fe37f6601c5f5752b750fdb01a.png" />
<img alt="../_images/d6f95bc4cd9a599133e8833c0bd985835698031d5d291e61428cc6dd9e24babe.png" src="../_images/d6f95bc4cd9a599133e8833c0bd985835698031d5d291e61428cc6dd9e24babe.png" />
<img alt="../_images/06cad9443fd3b09ca2bde2f2954bce5225d7d4248b6d4b6e34eb2028f9c28bbe.png" src="../_images/06cad9443fd3b09ca2bde2f2954bce5225d7d4248b6d4b6e34eb2028f9c28bbe.png" />
</div>
</div>
</section>
<section id="conclusion-final">
<h3><strong>Conclusion final</strong><a class="headerlink" href="#conclusion-final" title="Permalink to this heading">#</a></h3>
<p>A lo largo del estudio se evaluaron diez configuraciones de modelos, incluyendo variantes clásicas, polinómicas y optimizadas de regresión lineal, KNN, Ridge y Lasso, además de Random Forest y XGBoost. Se compararon según <strong>R²</strong>, <strong>MSE</strong>, <strong>MAE</strong> y <strong>tiempo de entrenamiento</strong>.</p>
</section>
<hr class="docutils" />
<section id="graficas-de-comparacion">
<h3><strong>Gráficas de Comparación</strong><a class="headerlink" href="#graficas-de-comparacion" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>R² (Bondad de ajuste)</strong><br />
Los modelos que más explican la variabilidad del <code class="docutils literal notranslate"><span class="pre">SolarIndex</span></code> son:</p>
<ul class="simple">
<li><p><strong>KNN Optimizado</strong> y <strong>Random Forest</strong> (~1.0)</p></li>
<li><p><strong>XGBoost</strong> (0.80)</p></li>
<li><p><strong>Ridge/Lin. Poly</strong> (~0.58)</p></li>
</ul>
</li>
<li><p><strong>MSE (Error Cuadrático Medio)</strong></p>
<ul class="simple">
<li><p><strong>KNN Optimizado</strong> y <strong>Random Forest</strong> tienen los errores más bajos.</p></li>
<li><p>Los modelos lineales simples y Lasso tienen errores más elevados.</p></li>
</ul>
</li>
<li><p><strong>MAE (Error Absoluto Medio)</strong></p>
<ul class="simple">
<li><p>Similar tendencia al MSE.</p></li>
<li><p><strong>XGBoost</strong> y modelos polinómicos de Ridge destacan por su equilibrio entre precisión y simplicidad.</p></li>
</ul>
</li>
<li><p><strong>Tiempo de Entrenamiento</strong></p>
<ul class="simple">
<li><p><strong>Linear Regression</strong> (0.36s) y <strong>XGBoost</strong> (2.4s) son los más eficientes.</p></li>
<li><p><strong>KNN Optimizado</strong> (164s), <strong>Ridge Poly</strong> (99s), <strong>Lasso Poly</strong> (258s) y <strong>Random Forest</strong> (1910s) muestran los mayores costos computacionales.</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="conclusion-global">
<h3><strong>Conclusión Global</strong><a class="headerlink" href="#conclusion-global" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Mejor Modelo Global</strong>:<br />
<strong>XGBoost</strong>, por su equilibrio entre rendimiento (R² alto) y eficiencia computacional, candidato a superar con el modelo propuesto.</p></li>
<li><p><strong>Modelos con Mejora Significativa</strong>:</p>
<ul>
<li><p><strong>Ridge Poly</strong>: duplicó su R² con términos polinómicos.</p></li>
<li><p><strong>Lasso Poly</strong>: incrementó su rendimiento a costa de mucho tiempo.</p></li>
<li><p><strong>Linear Poly</strong>: mejora considerable con bajo impacto en el tiempo.</p></li>
</ul>
</li>
<li><p><strong>Cuidado con el Overfitting</strong>:</p>
<ul>
<li><p><strong>Random Forest</strong> y <strong>KNN Optimizado</strong> deben validarse externamente para confirmar su generalización.</p></li>
</ul>
</li>
<li><p><strong>Modelos Base Recomendados</strong>:</p>
<ul>
<li><p><strong>Linear Poly</strong> y <strong>Ridge Poly</strong>, por ser explicables y computacionalmente viables.</p></li>
</ul>
</li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="eda.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Exploración de Datos (EDA)</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="metodologia_modelos_clasificacion.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Modelos de clasificación</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#librerias"><strong>Librerias:</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-problema-evaluacion-del-potencial-de-energia-solar-en-barranquilla-analisis-de-irradiancia-y-variables-atmosfericas-para-la-generacion-sostenible"><strong>Caso problema: Evaluación del potencial de energía Solar en Barranquilla: Análisis de irradiancia y variables atmosféricas para la generación sostenible</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contextualizacion"><strong>Contextualización</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-para-el-caso-de-regresion-y-benchmark"><strong>Modelos para el caso de regresión y Benchmark</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knn"><strong>KNN</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion"><strong>Evaluación</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-del-modelo"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-resultados-numericos"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-visual-actual-vs-predicted"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lineal-regression"><strong>Lineal Regression</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evalucion"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id2"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-regressor"><strong>SVM Regressor</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><strong>Análisis del modelo</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression"><strong>Ridge Regression</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id9"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id10"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id11"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso-regression"><strong>Lasso Regression</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id12"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id13"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id14"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id15"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id16"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest"><strong>Random Forest</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id17"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id18"><strong>Análisis del modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id19"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id20"><strong>Análisis Visual (Actual vs Predicted)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id21"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost"><strong>XGBoost</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id22"><strong>Evalución</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id23"><strong>Análisis del modelo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id24"><strong>Interpretación de Resultados Numéricos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id25"><strong>Análisis Visual (Actual vs Predicted)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id26"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resultados"><strong>Resultados</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-grafica-de-los-modelos"><strong>Comparacion grafica de los modelos</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id27"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-finales-del-analisis-de-modelos-de-regresion"><strong>Conclusiones Finales del Análisis de Modelos de Regresión</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id28"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id29"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-segun-r2-bondad-de-ajuste">Comparación según R² (Bondad de ajuste)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id30"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id31"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-segun-mse-error-cuadratico-medio">Comparación según MSE (Error Cuadrático Medio)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id32"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id33"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-segun-mae-error-absoluto-medio">Comparación según MAE (Error Absoluto Medio)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id34"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id35"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-segun-tiempo-de-entrenamiento">Comparación según Tiempo de Entrenamiento</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id36"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id37"></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#recomendacion-final"><strong>Recomendación Final</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id38"></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-and-lasso-regression-optimized"><strong>Ridge and Lasso Regression (optimized)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-lasso-y-ridge-mejorados"><strong>Análisis de Lasso y Ridge mejorados:</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-de-modelos-lineales-antes-vs-despues-de-la-optimizacion"><strong>Comparación de Modelos Lineales: Antes vs Después de la Optimización</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression-optimizado">1. Ridge Regression (Optimizado)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso-regression-optimizado">2. Lasso Regression (Optimizado)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-comparativa">Conclusión Comparativa</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knn-and-regression-optimized"><strong>KNN and Regression (optimized)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analsis-de-regresion-lineal-y-knn-mejorados"><strong>Análsis de Regresion lineal y KNN mejorados</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-de-modelos-lineal-y-knn-antes-vs-despues-de-la-optimizacion"><strong>Comparación de Modelos: Lineal y KNN - Antes vs Después de la Optimización</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-con-y-sin-polynomialfeatures">1. Linear Regression (con y sin PolynomialFeatures)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbors-knn">2. K-Nearest Neighbors (KNN)</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id39">Conclusión Comparativa</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-final-con-todos-los-modelos-optimizados-y-no-optimizados"><strong>Análisis final con todos los modelos optimizados y no optimizados</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-final"><strong>Conclusion final</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graficas-de-comparacion"><strong>Gráficas de Comparación</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-global"><strong>Conclusión Global</strong></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Eliana Rodríguez - Jesús Arévalo
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>