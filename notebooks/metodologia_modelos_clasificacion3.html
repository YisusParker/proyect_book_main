

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Evaluacion y analisis de modelos, casos porblema de regresión y clasificación &#8212; Analisis de localidades y aprovechamiento solar en Barranquilla: Análisis climático por localidad y estimación del potencial energético</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/metodologia_modelos_clasificacion3';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Modelos de Regresión" href="metodologia_modelos_regresion.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Analisis de localidades y aprovechamiento solar en Barranquilla: Análisis climático por localidad y estimación del potencial energético - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Analisis de localidades y aprovechamiento solar en Barranquilla: Análisis climático por localidad y estimación del potencial energético - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Contextualización:
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="eda.html">Exploración de Datos (EDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="metodologia_modelos_regresion.html">Modelos de Regresión</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Evaluacion y analisis de modelos, casos porblema de regresión y clasificación</strong></a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/YisusParker/jbook_ml20251" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/metodologia_modelos_clasificacion3.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Evaluacion y analisis de modelos, casos porblema de regresión y clasificación</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Evaluacion y analisis de modelos, casos porblema de regresión y clasificación</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#librerias"><strong>Librerias:</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-de-clasificacion"><strong>MODELOS DE CLASIFICACIÓN</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#balanceo-de-clases"><strong>Balanceo de clases</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contextualizacion"><strong>Contextualización</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#verificacion-de-balance-de-clases"><strong>Verificación de balance de clases</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-benchmark"><strong>Modelos Benchmark</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion-de-los-modelos-sin-optimizacion"><strong>Implementación de los modelos (sin optimización)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knn-k-nearest-neighbors"><strong>KNN (K-Nearest Neighbors)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes"><strong>Bayes</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metrica-seleccionada"><strong>Métrica seleccionada</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge"><strong>Ridge</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso"><strong>Lasso</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest"><strong>Random Forest</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost"><strong>XGBoost</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-support-vector-machine"><strong>SVM (Support Vector Machine)</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion-de-los-modelos-con-optimizacion"><strong>Implementación de los modelos (con optimización)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizacion-de-knn-con-kd-trees-ball-trees-faiss"><strong>Optimización de KNN con KD-Trees, Ball Trees, FAISS</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#kd-tree"><strong>KD-Tree</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ball-trees"><strong>Ball Trees</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#faiss"><strong>FAISS</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizacion-de-bayes-con-partial-fit"><strong>Optimización de Bayes con Partial_fit</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizacion-de-ridge-con-solver-optimizado-saga"><strong>Optimización de Ridge con Solver optimizado saga</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizacion-de-random-forest-con-gridsearchcv"><strong>Optimización de Random Forest con GridSearchCV</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svc-optimizado-con-sgdclassifier-linearsvc-rbf-svm-con-fourier"><strong>SVC optimizado con SGDClassifier,  LinearSVC, RBF SVM con Fourier</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sgdclassifier"><strong>SGDClassifier</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#linearsvc"><strong>LinearSVC</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#fourier"><strong>Fourier</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones"><strong>Conclusiones</strong></a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="evaluacion-y-analisis-de-modelos-casos-porblema-de-regresion-y-clasificacion">
<h1><strong>Evaluacion y analisis de modelos, casos porblema de regresión y clasificación</strong><a class="headerlink" href="#evaluacion-y-analisis-de-modelos-casos-porblema-de-regresion-y-clasificacion" title="Permalink to this heading">#</a></h1>
<section id="librerias">
<h2><strong>Librerias:</strong><a class="headerlink" href="#librerias" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing necessary libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>  <span class="c1"># For data manipulation and analysis</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>  <span class="c1"># For data visualization</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>  <span class="c1"># For tracking execution time</span>

<span class="c1"># Importing modules from scikit-learn for model building and evaluation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>  <span class="c1"># For splitting data and hyperparameter tuning</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pipeline</span>  <span class="c1"># For creating machine learning pipelines</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>  <span class="c1"># For feature scaling</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span>  <span class="c1"># For regression models</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>  <span class="c1"># For ensemble regression model</span>

<span class="c1"># Importing XGBoost library for regression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBRegressor</span>  <span class="c1"># For gradient boosting regression</span>

<span class="c1"># Importing metrics for model evaluation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span>  <span class="c1"># For evaluating regression models</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;..\df_final.csv&#39;</span><span class="p">)</span>  <span class="c1"># Load the dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Filas disponibles:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Filas disponibles: 1535519
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="modelos-de-clasificacion">
<h1><strong>MODELOS DE CLASIFICACIÓN</strong><a class="headerlink" href="#modelos-de-clasificacion" title="Permalink to this heading">#</a></h1>
<section id="balanceo-de-clases">
<h2><strong>Balanceo de clases</strong><a class="headerlink" href="#balanceo-de-clases" title="Permalink to this heading">#</a></h2>
<p>En <em>Machine Learning</em>, una clase se refiere a una de las categorías en las que se agrupan las observaciones dentro de un problema de clasificación. En un conjunto de datos etiquetado, cada instancia está asociada a una clase específica, permitiendo que un modelo aprenda a predecir la categoría correcta para nuevas observaciones.
Cuando el número de ejemplos en cada clase está desproporcionado, se habla de un <strong>desbalance de clases</strong>. Esto ocurre cuando una clase tiene significativamente más ejemplos que otra(s), afectando el desempeño del modelo de clasificación. En estas situaciones, el algoritmo tiende a favorecer la clase mayoritaria, lo que puede llevar a una alta precisión global, pero con un desempeño deficiente en la clase minoritaria.</p>
<p>Para mitigar este problema, se emplean técnicas de balanceo de clases, cuyo objetivo es modificar la distribución de los datos o ajustar la forma en que el modelo aprende. En este estudio, se implementarán tres enfoques principales:</p>
<ul class="simple">
<li><p>SMOTE (Synthetic Minority Over-sampling Technique): Es una técnica de sobremuestreo que genera nuevas instancias sintéticas de la clase minoritaria a partir de interpolaciones entre ejemplos existentes.</p></li>
<li><p>ADASYN (Adaptive Synthetic Sampling): Similar a SMOTE, pero con la particularidad de generar más ejemplos en aquellas regiones donde la clase minoritaria es más dispersa, mejorando la representatividad del conjunto de datos.</p></li>
<li><p>Ajuste de pesos con <code class="docutils literal notranslate"><span class="pre">class_weight='balanced</span></code>: Método que modifica la función de costo del modelo para penalizar más los errores en la clase minoritaria, sin necesidad de generar nuevos datos.</p></li>
</ul>
</section>
<section id="contextualizacion">
<h2><strong>Contextualización</strong><a class="headerlink" href="#contextualizacion" title="Permalink to this heading">#</a></h2>
<p>Pasra la evaluación de los moodelos de clasificación, se eligió la variable <code class="docutils literal notranslate"><span class="pre">LOCALITY</span></code> como objetivo de los modelos de clasificación con el fin de explorar la posibilidad de identificar microclimas urbanos dentro de la ciudad de Barranquilla. Cada localidad representa una zona geográfica con características urbanas, ambientales y espaciales distintas (algunas más cercanas a cuerpos de agua, otras más densamente urbanizadas o con menor cobertura vegetal).</p>
<p>Al utilizar variables meteorológicas como temperatura, humedad, presión y viento como entradas del modelo, se busca evaluar si estas condiciones permiten distinguir de manera significativa entre las distintas zonas de la ciudad. Esta elección permite no solo explorar la variabilidad climática a escala intraurbana, sino también probar la capacidad de los modelos de ML para detectar patrones geográficos sutiles basados en datos atmosféricos.</p>
<section id="verificacion-de-balance-de-clases">
<h3><strong>Verificación de balance de clases</strong><a class="headerlink" href="#verificacion-de-balance-de-clases" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_counts</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="c1"># Mostrar el conteo</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_counts</span><span class="p">)</span>

<span class="c1"># Visualización del balance de clases</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">class_counts</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribución de clases - Locality&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Categoría&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cantidad de observaciones&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LOCALITY
Sur          307104
Occidente    307104
Oriente      307104
Norte        307104
Centro       307103
Name: count, dtype: int64
</pre></div>
</div>
<img alt="../_images/e763400bb1e96ba098d437c12cf1a966fdf7e28d1ec4b7f86b8c246f5148b8c6.png" src="../_images/e763400bb1e96ba098d437c12cf1a966fdf7e28d1ec4b7f86b8c246f5148b8c6.png" />
</div>
</div>
<p>La distribución de las clases en la variable “localidad” es bastante equilibrada, ya que cada localidad (Sur, Oriente, Occidente, Norte y Centro) tiene un número similar de registros, con una pequeña diferencia en la localidad Centro. Dado que no se observa un desbalance significativo entre las clases, no es necesario aplicar técnicas de balanceo de clases, como SMOTE o ADASYN, para este conjunto de datos.</p>
</section>
</section>
<section id="modelos-benchmark">
<h2><strong>Modelos Benchmark</strong><a class="headerlink" href="#modelos-benchmark" title="Permalink to this heading">#</a></h2>
<p>Ya teniendo la certeza de que las clases seencuentran balanceada, se procede entonces a ejecutar los modelos de referencia para el modelo de clasificación, en este caso ejecutaremos K-Nearest Neighbors (KNN), Clasificación de Bayes, Regresión Logística (Regularización L1/L2 - Ridge, Lasso respectivamente), Decision Tree, Random Forest, XGBoost (Lime), y Máquinas de Soporte Vectorial (SVM). Para cada caso analizaremos…</p>
</section>
<section id="implementacion-de-los-modelos-sin-optimizacion">
<h2><strong>Implementación de los modelos (sin optimización)</strong><a class="headerlink" href="#implementacion-de-los-modelos-sin-optimizacion" title="Permalink to this heading">#</a></h2>
<section id="knn-k-nearest-neighbors">
<h3><strong>KNN (K-Nearest Neighbors)</strong><a class="headerlink" href="#knn-k-nearest-neighbors" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Librerías necesarias ===</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Codificar variable objetivo: LOCALITY ===</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY&#39;</span><span class="p">])</span>

<span class="c1"># ===  Seleccionar variables de entrada (X) ===</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;T2M&#39;</span><span class="p">,</span> <span class="s1">&#39;RH2M&#39;</span><span class="p">,</span> <span class="s1">&#39;PRECTOTCORR&#39;</span><span class="p">,</span> <span class="s1">&#39;WS10M&#39;</span><span class="p">,</span> <span class="s1">&#39;WD10M&#39;</span><span class="p">,</span>
            <span class="s1">&#39;PS&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_UV_INDEX&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_SW_DIFF&#39;</span><span class="p">,</span>
            <span class="s1">&#39;T2MDEW&#39;</span><span class="p">,</span> <span class="s1">&#39;T2MWET&#39;</span><span class="p">,</span> <span class="s1">&#39;WS50M&#39;</span><span class="p">,</span> <span class="s1">&#39;SolarIndex&#39;</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span>

<span class="c1"># === División train/test ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># === Escalar ===</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy_vals</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">best_acc</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">):</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
        <span class="n">best_acc</span> <span class="o">=</span> <span class="n">acc</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="n">accuracy_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy para k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Mejor accuracy: </span><span class="si">{</span><span class="n">best_acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> con k=</span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Graficar resultados</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">accuracy_vals</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Accuracy vs K&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Valor de k&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>En el modelo KNN, el parámetro k indica la cantidad de vecinos cercanos que se consideran para clasificar una observación. Para encontrar el valor óptimo, se evaluaron diferentes valores de k entre 1 y 20, obteniendo como mejor resultado un accuracy del 22.09% con k=2. Este valor fue utilizado en la configuración final del modelo, al ser el que logró el mayor nivel de acierto al clasificar las localidades en función de las variables meteorológicas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Definir modelo KNN ===</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># === Validación cruzada ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento final y predicción (medimos tiempo) ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (KNN sin optimización): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>


<span class="c1"># === Reporte de clasificación ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.22099519 0.2218139  0.22179995 0.22197309 0.22196379]
Promedio de accuracy en CV: 0.22170918574600978
Tiempo de cómputo (KNN sin optimización): 20.1014 segundos
=== Classification Report ===
              precision    recall  f1-score   support

      Centro       0.19      0.34      0.24     92131
       Norte       0.34      0.48      0.40     92131
   Occidente       0.16      0.16      0.16     92131
     Oriente       0.18      0.11      0.14     92132
         Sur       0.10      0.01      0.03     92131

    accuracy                           0.22    460656
   macro avg       0.19      0.22      0.19    460656
weighted avg       0.19      0.22      0.19    460656
</pre></div>
</div>
</div>
</div>
<p>El modelo KNN fue evaluado mediante validación cruzada con 5 particiones (5-fold cross-validation), arrojando valores de precisión (accuracy) bastante consistentes entre los diferentes pliegues: 0.2210, 0.2218, 0.2218, 0.2220 y 0.2220. Estas puntuaciones reflejan un rendimiento estable, aunque modesto, con un promedio general de accuracy de 0.2217, es decir, el modelo logró clasificar correctamente la localidad en aproximadamente el 22.1% de los casos. Este desempeño limitado puede atribuirse a la similitud entre condiciones meteorológicas de distintas zonas de la ciudad, lo que dificulta que el modelo identifique patrones claramente diferenciables.</p>
<p>El tiempo de cómputo total para entrenar el modelo y realizar las predicciones fue de 22.05 segundos, lo que servirá como referencia para evaluar la eficiencia de versiones optimizadas del modelo, como aquellas que utilicen estructuras de datos como KD-Tree o Ball-Tree.</p>
<p>En cuanto a las métricas por clase, el modelo mostró mayor capacidad de predicción para la localidad Norte, alcanzando una precisión de 0.34, un recall de 0.48 y un F1-score de 0.40. Esto indica que, cuando el modelo predice “Norte”, acierta el 34% de las veces, y que de todos los casos reales de esa localidad, logra identificar correctamente el 48%. Por el contrario, otras zonas como Sur y Oriente presentaron desempeños notablemente más bajos, con F1-scores de apenas 0.03 y 0.14, respectivamente, lo cual revela una alta tasa de errores al clasificar estas localidades.</p>
<p>El accuracy global del modelo fue del 22%, lo que confirma que la tarea de clasificación entre zonas geográficas basándose únicamente en variables meteorológicas representa un reto considerable. Además, los promedios macro y ponderado (weighted) para precisión, recall y F1-score se ubicaron en torno a 0.19–0.22, indicando que el bajo rendimiento es consistente a lo largo de todas las clases, sin que una en particular esté sesgando los resultados generales.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ===  Matriz de Confusión ===</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlGnBu&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión - KNN (LOCALITY)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d4d76ee73e9c1f1cb2414128e34fa6c7b4edc6e1760541e111641bb204604154.png" src="../_images/d4d76ee73e9c1f1cb2414128e34fa6c7b4edc6e1760541e111641bb204604154.png" />
</div>
</div>
<p>La matriz de confusión presentada resume el desempeño del modelo KNN al clasificar las cinco localidades de Barranquilla: Centro, Norte, Occidente, Oriente y Sur. En ella, las filas representan las localidades reales y las columnas las predicciones del modelo. Los valores diagonales (de arriba a la izquierda hacia abajo a la derecha) indican las predicciones correctas, mientras que los demás representan errores de clasificación.</p>
<p>A simple vista, se observa que el modelo tiene un mejor desempeño reconociendo correctamente las muestras de la localidad Norte, con 44.074 predicciones acertadas. Sin embargo, también se perciben altos niveles de confusión entre localidades vecinas o climáticamente similares. Por ejemplo, se evidencia lo siguiente:</p>
<ul class="simple">
<li><p>Muchas observaciones de Centro fueron clasificadas como Occidente (21.916) u Oriente (17.055).</p></li>
<li><p>Un número considerable de observaciones reales de Oriente fueron clasificadas como Centro (42.305) o Occidente (18.921).</p></li>
<li><p>Las predicciones correctas para Sur fueron apenas 1.326 (muy por debajo de sus errores hacia Centro, Norte u Occidente, con más de 38.000, 20.000 y 19.000 respectivamente).</p></li>
</ul>
<p>Este patrón sugiere que el modelo sigue teniendo dificultades para distinguir claramente entre ciertas zonas de la ciudad, lo cual puede deberse a similitudes en sus variables meteorológicas o a la cercanía geográfica entre localidades que comparten microclimas.</p>
<p>En general, la matriz confirma lo que ya se había evidenciado en el classification report: el modelo tiende a confundirse con frecuencia, especialmente en zonas como Sur y Oriente, y acierta con mayor facilidad en localidades que presentan patrones climáticos más diferenciados (como Norte).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Curvas ROC por clase + AUC por clase ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">auc_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">):</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2"> (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adivinar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curvas ROC - KNN (LOCALITY)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Falsos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Verdaderos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2bf17aadb5ba1f86399e1462689c043910c094fa779c393321891b2ba2078efd.png" src="../_images/2bf17aadb5ba1f86399e1462689c043910c094fa779c393321891b2ba2078efd.png" />
</div>
</div>
<p>Las curvas ROC obtenidas evidencian una capacidad moderadamente limitada del modelo para distinguir entre las distintas localidades de Barranquilla, con excepción de la localidad Norte, que presenta un AUC de 0.63. Este valor sugiere un desempeño aceptable, aunque no óptimo, en la capacidad del modelo para identificar correctamente esta clase frente a las demás. Para el resto de las localidades, los valores de AUC se mantienen cercanos al umbral de referencia aleatoria (0.50), con Centro y Oriente en 0.48, Occidente en 0.47 y Sur en 0.45. Estos resultados confirman que, aunque el modelo muestra una ligera mejora general respecto a la ejecución anterior, sigue teniendo dificultades importantes para diferenciar entre la mayoría de las zonas geográficas. En conjunto, las curvas ROC refuerzan la conclusión de que el modelo logra cierto grado de discriminación para la localidad Norte, pero no presenta una capacidad robusta y generalizable para separar correctamente todas las clases. Esto limita su utilidad como clasificador efectivo en un contexto donde se requiere precisión en la identificación de microclimas urbanos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === AUC promedio (macro) ===</span>
<span class="n">auc_macro</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">auc_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC promedio (macro): </span><span class="si">{</span><span class="n">auc_macro</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC promedio (macro): 0.5015
</pre></div>
</div>
</div>
</div>
<p>Además, el AUC (Area Under the Curve) promedio (macro) calculado para el modelo fue de 0.5015, lo que indica que, en promedio, la capacidad del modelo para distinguir correctamente entre una clase y el resto es apenas ligeramente superior al azar (que sería 0.50).</p>
</section>
<section id="bayes">
<h3><strong>Bayes</strong><a class="headerlink" href="#bayes" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>

<span class="c1"># --- División y escalado ---</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># --- Entrenamiento y medición de tiempo ---</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">nb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de entrenamiento (Naive Bayes sin optimización): </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># --- Predicción y métricas ---</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tiempo de entrenamiento (Naive Bayes sin optimización): 0.2338 segundos

Reporte de Clasificación:
              precision    recall  f1-score   support

      Centro       0.25      0.03      0.06     92131
       Norte       0.31      0.99      0.47     92131
   Occidente       0.19      0.02      0.03     92131
     Oriente       0.25      0.28      0.26     92132
         Sur       0.24      0.11      0.15     92131

    accuracy                           0.28    460656
   macro avg       0.25      0.28      0.19    460656
weighted avg       0.25      0.28      0.19    460656
</pre></div>
</div>
</div>
</div>
<p>El modelo de Clasificación Bayesiana fue entrenado utilizando el algoritmo GaussianNB, obteniendo un tiempo de entrenamiento extremadamente bajo de 0.2045 segundos, lo cual representa una ventaja considerable en términos de eficiencia computacional. Sin embargo, en cuanto a desempeño predictivo, el modelo alcanzó una precisión global (accuracy) de 28%, lo que significa que logró clasificar correctamente la localidad correspondiente en menos de un tercio de los casos. Esto sugiere que, aunque el modelo es rápido, su capacidad para diferenciar entre zonas geográficas a partir de condiciones meteorológicas aún es limitada.</p>
<p>El análisis por clase revela un patrón de desempeño muy desigual. La clase “Norte” sobresale con un recall de 0.99, lo que indica que el modelo identificó correctamente casi todos los casos reales de esa localidad. No obstante, este resultado también sugiere un sesgo fuerte hacia dicha clase, ya que las demás localidades presentan valores de recall significativamente más bajos: Centro (0.03), Occidente (0.02), Oriente (0.28) y Sur (0.11). En cuanto al F1-score, que equilibra precisión y recall, solo Norte alcanza un valor destacable de 0.47, mientras que las demás clases tienen puntuaciones muy bajas (de 0.03 a 0.26), reflejando una falta de equilibrio en la predicción.</p>
<p>El promedio macro de recall fue 0.28, ligeramente superior al de precisión (0.25) y F1-score (0.19). Debido al fuerte desequilibrio entre clases, se opta por utilizar recall macro promedio como métrica principal de validación, ya que permite evaluar qué tan bien se están reconociendo correctamente todas las clases sin verse influenciado por el tamaño de cada una.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Matriz de confusión con nombres correctos ---</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión - Naive Bayes&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6c460b0272a9a1a017879fef5c66096808a73c1ef09bbee9edd3fa3961336be3.png" src="../_images/6c460b0272a9a1a017879fef5c66096808a73c1ef09bbee9edd3fa3961336be3.png" />
</div>
</div>
<p>La matriz de confusión muestra que el modelo Naive Bayes tiene un fuerte sesgo hacia la clase “Norte”, ya que la mayoría de las predicciones, sin importar la clase real, terminan clasificadas como “Norte”. Por ejemplo, de los casos reales de “Occidente”, más de 52 mil fueron clasificados incorrectamente como “Norte”, y solo unos 2.900 fueron correctamente identificados. Esta tendencia se repite en todas las demás clases.</p>
<p>Aunque el modelo logra identificar con precisión casi todos los casos reales de “Norte” (lo que se ve en la celda [Norte, Norte] con más de 91 mil aciertos), su capacidad para diferenciar entre las otras localidades es muy baja, ya que la mayoría son absorbidas por esa clase dominante.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">label_binarize</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span>
    <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span>
    <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
<span class="p">)</span>
<span class="c1"># --- ROC y AUC ---</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">y_test_bin</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
<span class="n">y_score</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># ROC por clase</span>
<span class="n">fpr</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">tpr</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)):</span>
    <span class="n">fpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test_bin</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">y_score</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">roc_auc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="c1"># Micro y macro promedio</span>
<span class="n">fpr</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">],</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test_bin</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_score</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
<span class="n">roc_auc</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">])</span>

<span class="c1"># Curvas ROC con nombres</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1"> (AUC = </span><span class="si">{</span><span class="n">roc_auc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Falso Positivo&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Verdadero Positivo&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curvas ROC por Localidad - Naive Bayes&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># --- Tabla resumen de métricas ---</span>
<span class="n">metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Modelo&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Clasificación Bayesiana&quot;</span><span class="p">],</span>
    <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">)],</span>
    <span class="s2">&quot;recall&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">)],</span>
    <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)],</span>
    <span class="s2">&quot;f1-score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">)],</span>
    <span class="s2">&quot;AUC&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test_bin</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;ovr&quot;</span><span class="p">)]</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5a337a67896cb5e52c971578eb6373fa1f2722988db1492d7214b6f5e37dd6a9.png" src="../_images/5a337a67896cb5e52c971578eb6373fa1f2722988db1492d7214b6f5e37dd6a9.png" />
</div>
</div>
<p>Las curvas ROC por localidad confirman el comportamiento desigual del modelo Naive Bayes. La única clase con una curva claramente separada de la línea base (AUC &gt; 0.7) es Norte, lo que indica que el modelo tiene una capacidad real de distinguir correctamente los casos de esa clase. Su AUC de 0.72 respalda lo observado en la matriz de confusión y el classification report, predice muy bien “Norte”, pero “descuida” las demás.</p>
<p>Para las otras localidades, los valores de AUC se encuentran entre 0.55 y 0.56, muy cercanos al azar (0.5), lo cual refleja que el modelo no tiene una capacidad significativa de discriminar entre clases en esos casos. Esto refuerza la conclusión de que, aunque el modelo es rápido, no está captando patrones diferenciadores suficientes para predecir con fiabilidad la localidad en función de las variables meteorológicas disponibles.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Tabla de métricas&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">metrics_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tabla de métricas
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Modelo</th>
      <th>precision</th>
      <th>recall</th>
      <th>accuracy</th>
      <th>f1-score</th>
      <th>AUC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Clasificación Bayesiana</td>
      <td>0.246438</td>
      <td>0.283761</td>
      <td>0.283761</td>
      <td>0.192059</td>
      <td>0.586175</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>La tabla de métricas del modelo Naive Bayes muestra un rendimiento modesto y consistente con el resto de las evaluaciones. El accuracy general fue de 0.2837, lo que significa que el modelo acierta la predicción de la localidad en aproximadamente un 28% de los casos. La precisión (0.246) y el <strong>recall macro promedio</strong> (0.283) son similares, lo que indica que el modelo no solo comete errores al clasificar, sino que también deja de identificar correctamente muchas muestras de clases diferentes a la dominante.</p>
<p>El F1-score promedio fue de apenas 0.192, reflejando la incapacidad del modelo para balancear precisión y sensibilidad en la mayoría de las clases. Por otro lado, el AUC macro promedio fue 0.586, apenas por encima del valor aleatorio (0.5), lo que sugiere que la capacidad del modelo para distinguir entre clases es limitada.</p>
<section id="metrica-seleccionada">
<h4><strong>Métrica seleccionada</strong><a class="headerlink" href="#metrica-seleccionada" title="Permalink to this heading">#</a></h4>
<p>Para evaluar el desempeño del modelo Naive Bayes, se seleccionó el recall macro promedio como métrica principal de validación. Esta métrica calcula el recall de cada clase por separado y luego hace un promedio simple, sin ponderar por la cantidad de muestras en cada clase. Es decir, todas las clases tienen el mismo peso, lo que permite medir de forma justa qué tan bien el modelo logra identificar correctamente cada una, independientemente de su frecuencia.</p>
<p>Esta elección la consideramos adecuada en este caso porque el modelo mostró un comportamiento muy sesgado hacia la clase “Norte”, mientras que el desempeño en las demás localidades fue considerablemente inferior. Usar métricas como accuracy o recall ponderado podría ocultar ese desequilibrio, ya que se verían influidas por la clase dominante. En cambio, el recall macro permite visibilizar este problema y refleja de forma más “honesta” la capacidad del modelo para distinguir entre todas las zonas geográficas involucradas en la clasificación.</p>
</section>
</section>
<section id="ridge">
<h3><strong>Ridge</strong><a class="headerlink" href="#ridge" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>


<span class="c1"># === Codificar variable objetivo: LOCALITY ===</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY&#39;</span><span class="p">])</span>

<span class="c1"># === Seleccionar variables de entrada (X) ===</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;T2M&#39;</span><span class="p">,</span> <span class="s1">&#39;RH2M&#39;</span><span class="p">,</span> <span class="s1">&#39;PRECTOTCORR&#39;</span><span class="p">,</span> <span class="s1">&#39;WS10M&#39;</span><span class="p">,</span> <span class="s1">&#39;WD10M&#39;</span><span class="p">,</span>
            <span class="s1">&#39;PS&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_UV_INDEX&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_SW_DIFF&#39;</span><span class="p">,</span>
            <span class="s1">&#39;T2MDEW&#39;</span><span class="p">,</span> <span class="s1">&#39;T2MWET&#39;</span><span class="p">,</span> <span class="s1">&#39;WS50M&#39;</span><span class="p">,</span> <span class="s1">&#39;SolarIndex&#39;</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span>

<span class="c1"># === División train/test ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># === Escalar ===</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Definir modelo: Ridge (L2) ===</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span>
    <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span>      <span class="c1"># Ridge</span>
    <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span>     <span class="c1"># Elegido automáticamente por sklearn</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>      
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>         
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># === Validación cruzada (accuracy) ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">ridge</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento final y predicción ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (Ridge): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Reporte de clasificación ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.28529629 0.2849102  0.28444502 0.28484175 0.28634427]
Promedio de accuracy en CV: 0.2851675058598195
Tiempo de cómputo (Ridge): 16.7886 segundos
=== Classification Report ===
              precision    recall  f1-score   support

      Centro       0.25      0.07      0.10     92131
       Norte       0.30      1.00      0.47     92131
   Occidente       0.25      0.17      0.20     92131
     Oriente       0.25      0.13      0.17     92132
         Sur       0.24      0.06      0.09     92131

    accuracy                           0.28    460656
   macro avg       0.26      0.28      0.21    460656
weighted avg       0.26      0.28      0.21    460656
</pre></div>
</div>
</div>
</div>
<p>El modelo Ridge fue evaluado utilizando validación cruzada de 5 pliegues, obteniendo un promedio de accuracy de 0.2851, lo cual indica un rendimiento general limitado en la tarea de clasificación multiclase de la variable LOCALITY. Este comportamiento se refleja también en la evaluación sobre el conjunto de prueba, donde el modelo alcanzó una exactitud total del 28 %, apenas por encima del azar considerando que existen cinco clases aproximadamente balanceadas.</p>
<p>El análisis por clase muestra un desempeño marcadamente sesgado hacia la clase ‘Norte’, con un recall de 1.00 y un f1-score de 0.47, lo que implica que el modelo tiende a predecir esta clase de forma sistemática, muchas veces incorrectamente. Las demás localidades presentan valores de recall muy bajos (entre 0.06 y 0.17), lo que evidencia una fuerte desproporción en la capacidad de detección entre clases. Esto también se refleja en las métricas macro-promediadas: recall macro de 0.28 y f1-score macro de 0.21, confirmando que el modelo no logra un desempeño balanceado.</p>
<p>A pesar de su bajo tiempo de cómputo (16.7 segundos), el modelo Ridge sin optimización muestra limitaciones claras para capturar patrones diferenciadores entre localidades a partir de las variables meteorológicas, sugiriendo que una estrategia más robusta de ajuste de hiperparámetros u otros enfoques más complejos son necesarios para mejorar la clasificación.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Matriz de Confusión ===</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlGnBu&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión - Ridge Logistic Regression (LOCALITY)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/48f210310dbf06611cd2d3f6e2b74b92d4c72bc6600d0ea296a493ed6e81284e.png" src="../_images/48f210310dbf06611cd2d3f6e2b74b92d4c72bc6600d0ea296a493ed6e81284e.png" />
</div>
</div>
<p>La matriz de confusión refuerza la tendencia observada en el reporte de clasificación: el modelo presenta una fuerte inclinación hacia predecir la clase ‘Norte’, con más de 91,000 aciertos exactos y miles de instancias de otras clases mal clasificadas como tal. Por ejemplo, de los 92,131 ejemplos reales de la clase ‘Centro’, más de 52,000 fueron clasificados como ‘Norte’, evidenciando un sesgo sistemático que compromete la discriminación entre clases. Este patrón de sobrepredicción se replica en las demás clases, con la mayoría de los errores apuntando hacia la clase ‘Norte’, lo que sugiere que el modelo ha capturado patrones globales comunes en lugar de diferencias sutiles entre localidades.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Curvas ROC por clase + AUC por clase ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">auc_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">):</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2"> (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adivinar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curvas ROC - Ridge Logistic Regression (LOCALITY)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Falsos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Verdaderos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># === AUC promedio (macro) ===</span>
<span class="n">auc_macro</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">auc_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC promedio (macro): </span><span class="si">{</span><span class="n">auc_macro</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/50ff1ee36338cdac4513678f095817ec03a73e73a5be7ac5554821b26201764a.png" src="../_images/50ff1ee36338cdac4513678f095817ec03a73e73a5be7ac5554821b26201764a.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC promedio (macro): 0.6008
</pre></div>
</div>
</div>
</div>
<p>Las curvas ROC por clase permiten observar la capacidad del modelo para separar correctamente los ejemplos positivos de negativos en un marco binario por clase. En este caso, solo la clase ‘Norte’ alcanza un AUC aceptable (0.76), lo que indica una buena capacidad de discriminación para esa localidad en particular. Las demás clases presentan AUCs significativamente más bajos: entre 0.53 y 0.58, lo que es apenas superior a la línea base de azar (0.5). El AUC macro promedio de 0.6008 refleja esta desigualdad, indicando que, en promedio, el modelo tiene una capacidad de clasificación pobre o marginal para distinguir correctamente entre todas las clases.</p>
<p>Todos estos resultados muestran que el modelo Ridge no optimizado tiene un comportamiento desbalanceado y poco robusto, que favorece en exceso una clase dominante y falla al capturar las particularidades meteorológicas que distinguen entre zonas de la ciudad. Aunque el valor de AUC macro puede parecer moderadamente aceptable, la matriz de confusión y las métricas por clase demuestran que el modelo no es confiable para una clasificación multiclase equitativa.</p>
</section>
<section id="lasso">
<h3><strong>Lasso</strong><a class="headerlink" href="#lasso" title="Permalink to this heading">#</a></h3>
<p>La regresión Lasso se implementa como una regresión logística con penalización L1, la cual tiene como objetivo inducir <strong>sparsity</strong> en los coeficientes del modelo, es decir, forzar que algunos pesos se vuelvan exactamente cero. Esto actúa como un mecanismo de selección automática de variables, útil cuando se sospecha que algunas variables pueden ser irrelevantes o redundantes. En el contexto del presente proyecto, esta propiedad es valiosa para evaluar qué combinaciones de condiciones meteorológicas tienen un mayor poder discriminativo sobre la variable <code class="docutils literal notranslate"><span class="pre">LOCALITY</span></code>, especialmente en un entorno con múltiples predictores correlacionados.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Codificar variable objetivo: LOCALITY ===</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY&#39;</span><span class="p">])</span>

<span class="c1"># === Seleccionar variables de entrada (X) ===</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;T2M&#39;</span><span class="p">,</span> <span class="s1">&#39;RH2M&#39;</span><span class="p">,</span> <span class="s1">&#39;PRECTOTCORR&#39;</span><span class="p">,</span> <span class="s1">&#39;WS10M&#39;</span><span class="p">,</span> <span class="s1">&#39;WD10M&#39;</span><span class="p">,</span>
            <span class="s1">&#39;PS&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_UV_INDEX&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_SW_DIFF&#39;</span><span class="p">,</span>
            <span class="s1">&#39;T2MDEW&#39;</span><span class="p">,</span> <span class="s1">&#39;T2MWET&#39;</span><span class="p">,</span> <span class="s1">&#39;WS50M&#39;</span><span class="p">,</span> <span class="s1">&#39;SolarIndex&#39;</span><span class="p">]</span>

<span class="c1"># === Usar todo el dataset completo ===</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span>

<span class="c1"># === 3. Tomar muestra del dataset (sin modificar df) ===</span>
<span class="c1">#df_sampled = df.sample(n=150000, random_state=42)</span>
<span class="c1">#X = df_sampled[features]</span>
<span class="c1">#y = df_sampled[&#39;LOCALITY_encoded&#39;]</span>

<span class="c1"># === División train/test ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># === Escalar ===</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Definir modelo: Lasso (L1) ===</span>
<span class="n">lasso</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span>
    <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span>        
    <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">,</span>       
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span>
     <span class="n">tol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>       
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>           
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>


<span class="c1"># === Validación cruzada (accuracy) ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lasso</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento final y predicción ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lasso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">lasso</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (Lasso): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Reporte de clasificación ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.28480321 0.28377517 0.28435199 0.28445565 0.28603725]
Promedio de accuracy en CV: 0.284684653880163
Tiempo de cómputo (Lasso): 90.6186 segundos
=== Classification Report ===
              precision    recall  f1-score   support

      Centro       0.25      0.07      0.11     92131
       Norte       0.30      1.00      0.47     92131
   Occidente       0.25      0.18      0.21     92131
     Oriente       0.25      0.13      0.17     92132
         Sur       0.24      0.06      0.09     92131

    accuracy                           0.28    460656
   macro avg       0.26      0.28      0.21    460656
weighted avg       0.26      0.28      0.21    460656
</pre></div>
</div>
</div>
</div>
<p>El modelo Lasso fue evaluado con validación cruzada de cinco pliegues, obteniendo un promedio de accuracy de 0.2847, prácticamente idéntico al obtenido con Ridge, lo que sugiere que la penalización L1 no generó una mejora significativa en términos de desempeño general. En el conjunto de prueba, el modelo alcanzó una accuracy de 0.28, lo que indica un rendimiento bajo para un problema de clasificación con cinco clases, donde el mínimo esperado por azar sería del 20 %.</p>
<p>Al igual que en el modelo Ridge, la clase ‘Norte’ fue la única bien reconocida, con un recall de 1.00 y un f1-score de 0.47, mientras que las demás localidades obtuvieron valores de recall muy bajos, entre 0.06 y 0.18, con f1-scores cercanos a 0.10. Esta fuerte asimetría revela que el modelo tiende a concentrar la predicción en una sola clase, incurriendo en una alta tasa de falsos positivos para el resto. Las métricas macro-promediadas (recall macro de 0.28 y f1-score macro de 0.21) reflejan esta falta de balance, indicando que el modelo es incapaz de ofrecer una clasificación equitativa entre todas las localidades.</p>
<p>En términos computacionales, el tiempo de entrenamiento del modelo fue considerablemente mayor (90.6 segundos) en comparación con Ridge, debido a la naturaleza más compleja de la optimización L1, especialmente en problemas multiclase con gran volumen de datos. A pesar de esto, la penalización L1 no logró mejorar la capacidad predictiva ni la discriminación entre clases. El modelo tiende a comportarse de manera muy similar al Ridge, con diferencias marginales y un patrón de error prácticamente idéntico. Esto sugiere que, sin un ajuste fino de hiperparámetros o un proceso explícito de selección de variables, la penalización L1 no aporta ventajas claras en este caso.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Matriz de Confusión ===</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlOrBr&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión - Lasso Logistic Regression (LOCALITY)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9666e8e3521c8d3aa8bcf7755ca07e631c8fc22d1c40c19aa6f39c8287069bbd.png" src="../_images/9666e8e3521c8d3aa8bcf7755ca07e631c8fc22d1c40c19aa6f39c8287069bbd.png" />
</div>
</div>
<p>La matriz de confusión evidencia nuevamente una fuerte inclinación del modelo a clasificar incorrectamente la mayoría de las muestras como pertenecientes a la clase ‘Norte’, reproduciendo el mismo patrón observado en el modelo Ridge. Por ejemplo, de los 92,131 ejemplos reales de la clase ‘Centro’, solo 6,135 fueron clasificados correctamente, mientras que más de 52,000 fueron erróneamente asignados a ‘Norte’. Esta tendencia se repite para las demás clases, lo cual revela una falta de sensibilidad generalizada del modelo para diferenciar entre las localidades, salvo por ‘Norte’.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Curvas ROC por clase + AUC por clase ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">auc_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">):</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2"> (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adivinar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curvas ROC - Lasso Logistic Regression (LOCALITY)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Falsos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Verdaderos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># === AUC promedio (macro) ===</span>
<span class="n">auc_macro</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">auc_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC promedio (macro): </span><span class="si">{</span><span class="n">auc_macro</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6b3786ce4b1f034ad6b29da7bd4586b3b46a248af06cf7e0a5d456bde64f7566.png" src="../_images/6b3786ce4b1f034ad6b29da7bd4586b3b46a248af06cf7e0a5d456bde64f7566.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC promedio (macro): 0.6007
</pre></div>
</div>
</div>
</div>
<p>Analizando las curvas ROC se observa que el modelo discrimina relativamente bien la clase ‘Norte’, con un <strong>AUC de 0.76</strong>, mientras que las otras clases presentan valores cercanos a 0.5. En particular, las curvas correspondientes a ‘Occidente’ y ‘Sur’ muestran un comportamiento casi aleatorio, con AUC’s de 0.53 y 0.56 respectivamente. La clase ‘Centro’ y ‘Oriente’ se sitúan en un punto intermedio, con un AUC de 0.58 cada una. Este comportamiento se resume en un AUC promedio (macro) de 0.6007, lo cual indica que, en promedio, el modelo tiene una capacidad de discriminación débil, apenas por encima del azar (QUE ES 0.5). Como conclusión para este modelo se llegó a que los resultados sugieren que la penalización L1 no contribuyó a una mejora significativa del rendimiento. La matriz de confusión confirma que la mayor parte de las predicciones recaen en una única clase, y las curvas ROC reflejan una baja capacidad del modelo para separar correctamente instancias positivas de negativas en la mayoría de las clases. Si bien el modelo fue computacionalmente más costoso que Ridge, su comportamiento es esencialmente el mismo, con diferencias mínimas en las métricas y en el patrón de error.</p>
</section>
<section id="random-forest">
<h3><strong>Random Forest</strong><a class="headerlink" href="#random-forest" title="Permalink to this heading">#</a></h3>
<p>Random Forest es un modelo de clasificación basado en un conjunto de árboles de decisión entrenados sobre subconjuntos aleatorios del conjunto de datos. Cada árbol contribuye con un voto, y la clase final se decide por mayoría. Esta técnica es conocida por su robustez ante el sobreajuste y su capacidad para modelar relaciones no lineales. En este proyecto, se utiliza como modelo de referencia para evaluar su rendimiento en la clasificación de <code class="docutils literal notranslate"><span class="pre">LOCALITY</span></code>, a partir de variables meteorológicas, sin ajuste de hiperparámetros.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;T2M&#39;</span><span class="p">,</span> <span class="s1">&#39;RH2M&#39;</span><span class="p">,</span> <span class="s1">&#39;PRECTOTCORR&#39;</span><span class="p">,</span> <span class="s1">&#39;WS10M&#39;</span><span class="p">,</span> <span class="s1">&#39;WD10M&#39;</span><span class="p">,</span>
            <span class="s1">&#39;PS&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_UV_INDEX&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_SW_DIFF&#39;</span><span class="p">,</span>
            <span class="s1">&#39;T2MDEW&#39;</span><span class="p">,</span> <span class="s1">&#39;T2MWET&#39;</span><span class="p">,</span> <span class="s1">&#39;WS50M&#39;</span><span class="p">,</span> <span class="s1">&#39;SolarIndex&#39;</span><span class="p">]</span>

<span class="c1"># === Usar todo el dataset completo ===</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span>

<span class="c1"># === Datos: X e y vienen de df_sampled ya tratado ===</span>
<span class="c1">#df_sampled = df.sample(n=150000, random_state=42)</span>
<span class="c1">#X = df_sampled[features]</span>
<span class="c1">#y = df_sampled[&#39;LOCALITY_encoded&#39;]</span>

<span class="c1"># === División train/test ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>



<span class="c1"># === Definir modelo Random Forest (no optimizado) ===</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Validación cruzada ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento y predicción (con tiempo) ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (Random Forest benchmark): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Reporte de clasificación ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.16825834 0.1684165  0.16794202 0.16675195 0.16791489]
Promedio de accuracy en CV: 0.16785673983880797
Tiempo de cómputo (Random Forest benchmark): 355.7430 segundos
=== Classification Report ===
              precision    recall  f1-score   support

      Centro       0.08      0.08      0.08     92131
       Norte       0.32      0.58      0.41     92131
   Occidente       0.05      0.03      0.04     92131
     Oriente       0.09      0.08      0.08     92132
         Sur       0.04      0.03      0.03     92131

    accuracy                           0.16    460656
   macro avg       0.12      0.16      0.13    460656
weighted avg       0.12      0.16      0.13    460656
</pre></div>
</div>
</div>
</div>
<p>El modelo Random Forest, arrojó un promedio de accuracy en validación cruzada de apenas 0.1678, el valor más bajo entre todos los modelos evaluados hasta el momento. Esta tendencia se mantuvo en el conjunto de prueba, con una exactitud global de 16 %, lo cual indica un desempeño deficiente incluso frente a una clasificación aleatoria. Esto sugiere que la configuración por defecto del modelo no está adaptada a la complejidad del problema, ni logra capturar patrones relevantes en los datos meteorológicos para distinguir entre localidades. El análisis por clase muestra que solo la clase ‘Norte’ fue reconocida con cierto nivel de acierto, alcanzando un recall de 0.58 y un f1-score de 0.41, mientras que el resto de las clases presenta recalls extremadamente bajos (entre 0.03 y 0.08), con f1-scores que no superan 0.08. Las métricas macro-promediadas (recall de 0.16 y f1-score de 0.13) reflejan una clara incapacidad del modelo para ofrecer una clasificación balanceada entre todas las clases. La métrica weighted avg, que pondera el soporte de cada clase, tampoco mejora significativamente.</p>
<p>En términos computacionales, el modelo fue notablemente más costoso que los anteriores, con un tiempo de entrenamiento superior a 355 segundos. Sin embargo, este mayor esfuerzo no se tradujo en un mejor desempeño. Por el contrario, la falta de ajuste en los hiperparámetros clave (como el número de árboles, su profundidad, o los criterios de división) probablemente limitó la capacidad del modelo para aprender representaciones útiles del fenómeno observado.</p>
<p>Con estos resultados notamos que el modelo Random Forest sin optimización resulta inadecuado para este problema específico, y sugiere la necesidad de un ajuste cuidadoso de hiperparámetros para poder aprovechar el potencial de este tipo de algoritmo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Matriz de Confusión ===</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlGnBu&#39;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión - Random Forest (benchmark)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/bbed32ebe0ddeea584d62f2e3bbba53405b109994ae639a7d41fc8289af6b58d.png" src="../_images/bbed32ebe0ddeea584d62f2e3bbba53405b109994ae639a7d41fc8289af6b58d.png" />
</div>
</div>
<p>La matriz de confusión revela un patrón de error disperso y poco estructurado. Aunque la clase ‘Norte’ sigue siendo la que presenta mayor cantidad de aciertos (53,639 casos correctamente clasificados), su desempeño está lejos del recall perfecto que mostraban los modelos Ridge y Lasso. Además, una proporción significativa de las instancias de ‘Norte’ se distribuyen erróneamente entre las demás clases, particularmente hacia ‘Centro’ y ‘Occidente’.</p>
<p>Las demás clases muestran una distribución de errores aún más crítica. Por ejemplo, la clase ‘Oriente’ tiene una alta cantidad de instancias mal clasificadas como ‘Centro’ (28,350) y como ‘Norte’ (23,500), mientras que sus aciertos apenas alcanzan los 7,198. La clase ‘Sur’ presenta un comportamiento similar, con más predicciones incorrectas hacia ‘Norte’ (28,584) y ‘Centro’ (23,012) que aciertos reales (2,566). Este patrón se repite también en las filas de ‘Centro’ y ‘Occidente’, lo que indica que el modelo tiene dificultades para generar reglas consistentes que permitan distinguir de forma confiable entre localidades. No obnstante, la matriz refleja un modelo que comete errores generalizados, sin un sesgo claro hacia una sola clase como en modelos anteriores, pero con un alto grado de confusión cruzada entre todas las etiquetas, lo que se traduce en un desempeño pobre y desbalanceado.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Curvas ROC y AUC ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">auc_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">):</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2"> (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adivinar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curvas ROC - Random Forest (benchmark)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Falsos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Verdaderos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># === AUC promedio (macro) ===</span>
<span class="n">auc_macro</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">auc_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC promedio (macro): </span><span class="si">{</span><span class="n">auc_macro</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/71b06f548f66c4a875b3b99d1def9922079208f8359488e57d532694eeb2d639.png" src="../_images/71b06f548f66c4a875b3b99d1def9922079208f8359488e57d532694eeb2d639.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC promedio (macro): 0.4625
</pre></div>
</div>
</div>
</div>
<p>Las curvas ROC para el modelo Random Forest reflejan una baja capacidad de discriminación entre clases. Solo la clase ‘Norte’ alcanza un valor aceptable de AUC (0.73), mientras que el resto de las clases se encuentran muy cerca o por debajo del umbral del azar. En particular, las curvas correspondientes a ‘Centro’, ‘Occidente’ y ‘Oriente’ muestran valores de 0.42, lo que indica que el modelo apenas mejora sobre una clasificación aleatoria. El caso de la clase ‘Sur’ es especialmente crítico, con un AUC de apenas 0.31, lo que sugiere que el modelo realiza más clasificaciones incorrectas que correctas para esa categoría.</p>
<p>El AUC promedio (macro) de 0.4625 confirma esta tendencia general de bajo rendimiento. Este valor representa el promedio de la capacidad del modelo para separar correctamente cada clase frente a las demás, y en este caso es inferior al 0.5, que marca el umbral de un modelo sin capacidad predictiva. La gran diferencia entre la clase mejor reconocida (‘Norte’) y las demás refleja un desequilibrio severo en la capacidad del modelo para aprender representaciones útiles para cada localidad.</p>
</section>
<section id="xgboost">
<h3><strong>XGBoost</strong><a class="headerlink" href="#xgboost" title="Permalink to this heading">#</a></h3>
<p>XGBoost es un modelo de boosting basado en árboles de decisión que construye secuencias de modelos débiles corrigiendo iterativamente los errores del anterior. Es reconocido por su capacidad de generalización, velocidad de entrenamiento y manejo eficiente de grandes volúmenes de datos. En este caso, se utilizó con su configuración base como modelo benchmark, para evaluar su rendimiento inicial sin ajustes sobre el conjunto de variables meteorológicas empleadas para predecir <code class="docutils literal notranslate"><span class="pre">LOCALITY</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="c1"># === Separar features y target) ===</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span>

<span class="c1"># === División train/test ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># === Definir modelo XGBoost (no optimizado) ===</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;mlogloss&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Validación cruzada (accuracy) ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">xgb</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento y predicción (con tiempo) ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (XGBoost benchmark): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Reporte de clasificación ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.28659878 0.28635689 0.28590567 0.28596747 0.28669315]
Promedio de accuracy en CV: 0.2863043941896197
Tiempo de cómputo (XGBoost benchmark): 11.2518 segundos
=== Classification Report ===
              precision    recall  f1-score   support

      Centro       0.21      0.19      0.20     92131
       Norte       0.36      0.87      0.51     92131
   Occidente       0.18      0.08      0.11     92131
     Oriente       0.21      0.18      0.19     92132
         Sur       0.17      0.07      0.10     92131

    accuracy                           0.28    460656
   macro avg       0.23      0.28      0.22    460656
weighted avg       0.23      0.28      0.22    460656
</pre></div>
</div>
</div>
</div>
<p>El modelo alcanzó un promedio de accuracy en validación cruzada de 0.2863, valor que se mantuvo prácticamente igual en el conjunto de prueba (accuracy total de 28 %). A pesar de tratarse de una configuración básica, este rendimiento ya supera el de varios modelos evaluados, lo que sugiere que incluso sin optimización, XGBoost logra captar algunas estructuras relevantes en los datos.</p>
<p>Sin embargo, el modelo también muestra un comportamiento desequilibrado. La clase ‘Norte’ vuelve a ser la más favorecida, con un recall de 0.87 y un f1-score de 0.51, mientras que las demás localidades presentan valores considerablemente más bajos. En particular, ‘Occidente’ y ‘Sur’ son las clases con menor desempeño, ambas con recalls inferiores al 0.10 y f1-scores cercanos a 0.10. Las métricas macro-promediadas (recall de 0.28 y f1-score de 0.22) confirman que, aunque el modelo mejora el reconocimiento de una clase dominante, sigue teniendo dificultades para distinguir correctamente entre todas las categorías.</p>
<p>En términos de eficiencia, el modelo completó el entrenamiento en apenas 11.25 segundos, lo que demuestra su buena relación entre costo computacional y rendimiento inicial. Esto lo posiciona como un modelo con potencial para ser optimizado, especialmente considerando que ya muestra señales de diferenciación entre clases sin ajustes previos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Matriz de Confusión ===</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlGnBu&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión - XGBoost (benchmark)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/432263b30411eaf59eb5be1ae1de18ce56f571c6ed3c5a76976bd5dbe4ed6b42.png" src="../_images/432263b30411eaf59eb5be1ae1de18ce56f571c6ed3c5a76976bd5dbe4ed6b42.png" />
</div>
</div>
<p>La matriz de confusión muestra que el modelo logra un buen reconocimiento de la clase ‘Norte’, con 80,208 predicciones correctas, pero sigue clasificando erróneamente una cantidad considerable de instancias de otras clases como si fueran ‘Norte’. Por ejemplo, más de 34,000 observaciones reales de ‘Sur’ fueron clasificadas como ‘Norte’, lo que refleja un sesgo hacia esa clase.</p>
<p>En las demás categorías, el modelo distribuye los errores de manera más equilibrada que modelos anteriores, aunque con bajo nivel de aciertos. La clase ‘Centro’ tuvo alrededor de 17,000 predicciones correctas, pero otras 23,000 fueron confundidas con ‘Oriente’. El resto de las clases sigue con niveles altos de confusión cruzada, especialmente ‘Occidente’ y ‘Oriente’, lo que indica que el modelo aún tiene dificultades para separar bien estas zonas.</p>
<p>Si bien no alcanza un rendimiento balanceado, la matriz sugiere que el modelo comienza a capturar algunas diferencias entre clases, y que con ajustes podría mejorar su precisión y reducir la confusión entre localidades.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Curvas ROC y AUC por clase ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">auc_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">):</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2"> (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adivinar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curvas ROC - XGBoost (benchmark)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Falsos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Verdaderos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/51ac1c55b1932c22e24d8fc03f6cec9012d90e47d7319054e926c43ec09ec04c.png" src="../_images/51ac1c55b1932c22e24d8fc03f6cec9012d90e47d7319054e926c43ec09ec04c.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === AUC promedio (macro) ===</span>
<span class="n">auc_macro</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">auc_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC promedio (macro): </span><span class="si">{</span><span class="n">auc_macro</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC promedio (macro): 0.6318
</pre></div>
</div>
</div>
</div>
<p>Las curvas ROC muestran una mejora general en la capacidad del modelo para distinguir entre clases, especialmente en comparación con los modelos anteriores. La clase ‘Norte’ se destaca nuevamente con un AUC de 0.79, lo que indica que el modelo logra identificar correctamente la mayoría de sus casos. Las demás clases alcanzan valores más moderados, entre 0.55 (‘Sur’) y 0.61 (‘Occidente’, ‘Oriente’), lo cual representa un progreso respecto a lo observado con modelos anteriores.</p>
<p>El AUC promedio (macro) fue de 0.6318, lo que sugiere que el modelo tiene una capacidad global aceptable para separar clases en un contexto multiclase, aunque todavía limitada en varias categorías. Si bien no hay un balance perfecto, el modelo demuestra un avance en la diferenciación de localidades, y esta base inicial justifica una posterior optimización para aprovechar mejor su potencial.</p>
</section>
<section id="svm-support-vector-machine">
<h3><strong>SVM (Support Vector Machine)</strong><a class="headerlink" href="#svm-support-vector-machine" title="Permalink to this heading">#</a></h3>
<p>Support Vector Machine (SVM) es un modelo supervisado que busca encontrar el hiperplano óptimo que maximiza la separación entre clases. Su principal ventaja es que puede modelar relaciones complejas incluso en espacios de alta dimensión, especialmente con el uso de kernels. En este caso, se utilizó un modelo SVM con su configuración básica y sin optimización, para evaluar su rendimiento inicial sobre el conjunto reducido de datos meteorológicos y la clasificación de <code class="docutils literal notranslate"><span class="pre">LOCALITY</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># === Tomar muestra del dataset completo ===</span>
<span class="n">df_sampled</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">75000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Separar features y target ===</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_sampled</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_sampled</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span>

<span class="c1"># === Separar features y target (dataset completo) ===</span>
<span class="c1">#X = df[features]</span>
<span class="c1">#y = df[&#39;LOCALITY_encoded&#39;]</span>

<span class="c1"># === División train/test ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># === Escalado obligatorio para SVM ===</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Definir SVM (benchmark) ===</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Validación cruzada ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento y predicción (con tiempo) ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (SVM benchmark): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="c1"># === Reporte de clasificación ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.28742857 0.28438095 0.29       0.28485714 0.28504762]
Promedio de accuracy en CV: 0.2863428571428571
Tiempo de cómputo (SVM benchmark): 560.4205 segundos
=== Classification Report ===
              precision    recall  f1-score   support

      Centro       0.25      0.08      0.13      4465
       Norte       0.31      1.00      0.47      4536
   Occidente       0.25      0.09      0.13      4513
     Oriente       0.26      0.15      0.19      4473
         Sur       0.24      0.10      0.14      4513

    accuracy                           0.29     22500
   macro avg       0.26      0.29      0.21     22500
weighted avg       0.26      0.29      0.21     22500
</pre></div>
</div>
</div>
</div>
<p>El modelo obtuvo un promedio de accuracy en validación cruzada de 0.2863, valor consistente con el resultado en el conjunto de prueba (exactitud del 29 %), lo que lo posiciona levemente por encima del rendimiento base observado en modelos anteriores. Sin embargo, al igual que otros clasificadores, SVM presenta un comportamiento fuertemente sesgado hacia la clase ‘Norte’, con un recall perfecto de 1.00 y un f1-score de 0.47. Este patrón implica que el modelo tiende a clasificar gran parte de las observaciones en esa categoría, lo que afecta la capacidad de distinguir correctamente el resto de las clases.</p>
<p>El desempeño en las demás localidades es bajo, con recalls que oscilan entre 0.08 (‘Centro’) y 0.15 (‘Oriente’), y f1-scores que no superan 0.19. Las métricas macro-promediadas (recall de 0.29 y f1-score de 0.21) indican que, si bien hay un ligero avance frente a modelos como Ridge o Lasso, el rendimiento sigue siendo limitado y desigual.</p>
<p>Un aspecto importante es el tiempo de cómputo, que fue considerablemente mayor (560 segundos), lo que resalta uno de los principales inconvenientes del SVM tradicional en conjuntos de datos de tamaño medio o grande. Aunque ofrece una mejora marginal en precisión global, su costo computacional y su tendencia a sobreajustar una sola clase limitan su utilidad práctica en este escenario sin ajustes adicionales.</p>
<p>Cabe resaltar que este modelo no fue entrenado con el conjunto completo de datos (1.5 millones de registros aprox), sino con una muestra de 75,000 instancias. Esto se debió a las limitaciones de tiempo de cómputo, ya que el algoritmo SVM, en su forma clásica, no escala bien con grandes volúmenes de datos. Esta restricción debe tenerse en cuenta al comparar los resultados con otros modelos que sí fueron ejecutados sobre la totalidad del dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Matriz de Confusión ===</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlGnBu&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión - SVM (benchmark)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c4ac8b92a93c243021bd05b146d9824e3d13e8bf595b57750c6630b283796821.png" src="../_images/c4ac8b92a93c243021bd05b146d9824e3d13e8bf595b57750c6630b283796821.png" />
</div>
</div>
<p>La matriz muestra una alta concentración de predicciones en la clase ‘Norte’, con 4,532 aciertos, lo que explica el recall perfecto observado en el reporte. Sin embargo, el resto de las clases se ven fuertemente afectadas por esto. Por ejemplo, la mayoría de los ejemplos reales de ‘Centro’, ‘Occidente’, ‘Oriente’ y ‘Sur’ fueron mal clasificados como ‘Norte’. En el caso de ‘Centro’, solo 376 instancias fueron correctamente clasificadas, mientras más de 2,500 se asignaron erróneamente a ‘Norte’.</p>
<p>Este patrón se repite con todas las clases no dominantes, que presentan pocas predicciones correctas y una distribución de errores bastante similar, lo que indica que el modelo no logra separar adecuadamente las clases más allá de ‘Norte’. Aunque el número total de errores es bajo en comparación con modelos que usaron más datos, la falta de balance entre clases resalta las limitaciones de SVM en esta configuración inicial.</p>
<p>El resultado reafirma que, si bien el modelo acierta con precisión en una clase muy representada, su generalización hacia el resto de las etiquetas es muy pobre, con alta confusión entre todas las demás.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Curvas ROC y AUC por clase ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">auc_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">):</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2"> (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adivinar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curvas ROC - SVM (benchmark)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Falsos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Verdaderos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># === AUC promedio (macro) ===</span>
<span class="n">auc_macro</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">auc_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC promedio (macro): </span><span class="si">{</span><span class="n">auc_macro</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/99d6674229adeb5eb81cd79cb4f0549f6d59287f55f6b8757597f3f5e0ed07bd.png" src="../_images/99d6674229adeb5eb81cd79cb4f0549f6d59287f55f6b8757597f3f5e0ed07bd.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC promedio (macro): 0.5886
</pre></div>
</div>
</div>
</div>
<p>Las curvas ROC muestran que el modelo tiene un desempeño claramente favorable solo en la clase ‘Norte’, con un AUC de 0.72, mientras que para el resto de las clases los valores se ubican apenas por encima del azar, entre 0.55 y 0.56. La clase ‘Centro’, por ejemplo, presenta un AUC de 0.55, lo que indica que el modelo apenas logra distinguir correctamente entre positivos y negativos para esa categoría. La falta de separación entre curvas evidencia una capacidad limitada para discriminar correctamente entre la mayoría de las clases.</p>
<p>El AUC promedio (macro) fue de 0.5886, lo cual confirma una leve capacidad de discriminación global del modelo, pero sin resultados satisfactorios en términos de balance o equidad entre etiquetas. Este comportamiento está alineado con lo observado en la matriz de confusión y el reporte de métricas.</p>
</section>
</section>
<section id="implementacion-de-los-modelos-con-optimizacion">
<h2><strong>Implementación de los modelos (con optimización)</strong><a class="headerlink" href="#implementacion-de-los-modelos-con-optimizacion" title="Permalink to this heading">#</a></h2>
<section id="optimizacion-de-knn-con-kd-trees-ball-trees-faiss">
<h3><strong>Optimización de KNN con KD-Trees, Ball Trees, FAISS</strong><a class="headerlink" href="#optimizacion-de-knn-con-kd-trees-ball-trees-faiss" title="Permalink to this heading">#</a></h3>
<section id="kd-tree">
<h4><strong>KD-Tree</strong><a class="headerlink" href="#kd-tree" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Definir modelo KNN con KD-Tree ===</span>
<span class="n">knn_kdtree</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;kd_tree&#39;</span><span class="p">)</span>

<span class="c1"># === Validación cruzada ===</span>
<span class="n">cv_scores_kdtree</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn_kdtree</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores (KD-Tree):&quot;</span><span class="p">,</span> <span class="n">cv_scores_kdtree</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV (KD-Tree):&quot;</span><span class="p">,</span> <span class="n">cv_scores_kdtree</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento final y predicción (medimos tiempo) ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">knn_kdtree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_kdtree</span> <span class="o">=</span> <span class="n">knn_kdtree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="n">y_proba_kdtree</span> <span class="o">=</span> <span class="n">knn_kdtree</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time_kdtree</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (KNN con KD-Tree): </span><span class="si">{</span><span class="n">elapsed_time_kdtree</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Reporte de clasificación ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report (KD-Tree) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_kdtree</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores (KD-Tree): [0.22099519 0.2218139  0.22179995 0.22197309 0.22196379]
Promedio de accuracy en CV (KD-Tree): 0.22170918574600978
Tiempo de cómputo (KNN con KD-Tree): 20.4023 segundos
=== Classification Report (KD-Tree) ===
              precision    recall  f1-score   support

      Centro       0.19      0.34      0.24     92131
       Norte       0.34      0.48      0.40     92131
   Occidente       0.16      0.16      0.16     92131
     Oriente       0.18      0.11      0.14     92132
         Sur       0.10      0.01      0.03     92131

    accuracy                           0.22    460656
   macro avg       0.19      0.22      0.19    460656
weighted avg       0.19      0.22      0.19    460656
</pre></div>
</div>
</div>
</div>
</section>
<section id="ball-trees">
<h4><strong>Ball Trees</strong><a class="headerlink" href="#ball-trees" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Definir modelo KNN con Ball-Tree ===</span>
<span class="n">knn_balltree</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ball_tree&#39;</span><span class="p">)</span>

<span class="c1"># === Validación cruzada ===</span>
<span class="n">cv_scores_balltree</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn_balltree</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores (Ball-Tree):&quot;</span><span class="p">,</span> <span class="n">cv_scores_balltree</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV (Ball-Tree):&quot;</span><span class="p">,</span> <span class="n">cv_scores_balltree</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento final y predicción (medimos tiempo) ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">knn_balltree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_balltree</span> <span class="o">=</span> <span class="n">knn_balltree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="n">y_proba_balltree</span> <span class="o">=</span> <span class="n">knn_balltree</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time_balltree</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (KNN con Ball-Tree): </span><span class="si">{</span><span class="n">elapsed_time_balltree</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Reporte de clasificación ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report (Ball-Tree) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_balltree</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores (Ball-Tree): [0.22099519 0.22180925 0.2218046  0.22196844 0.2219824 ]
Promedio de accuracy en CV (Ball-Tree): 0.22171197680717122
Tiempo de cómputo (KNN con Ball-Tree): 1216.6085 segundos
=== Classification Report (Ball-Tree) ===
              precision    recall  f1-score   support

      Centro       0.19      0.34      0.24     92131
       Norte       0.34      0.48      0.40     92131
   Occidente       0.16      0.16      0.16     92131
     Oriente       0.18      0.11      0.14     92132
         Sur       0.10      0.01      0.03     92131

    accuracy                           0.22    460656
   macro avg       0.19      0.22      0.19    460656
weighted avg       0.19      0.22      0.19    460656
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Aplicando el algoritmo de optimización sin hacer la validación cruzada</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span>

<span class="c1"># === Modelo con Ball-Tree ===</span>
<span class="n">knn_balltree</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ball_tree&#39;</span><span class="p">)</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">knn_balltree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_balltree</span> <span class="o">=</span> <span class="n">knn_balltree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">elapsed_time_balltree</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (Ball-Tree): </span><span class="si">{</span><span class="n">elapsed_time_balltree</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy (Ball-Tree): </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_balltree</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report (Ball-Tree) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_balltree</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="faiss">
<h4><strong>FAISS</strong><a class="headerlink" href="#faiss" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">faiss</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>

<span class="c1"># === Preparar datos para FAISS ===</span>
<span class="n">X_train_faiss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="n">X_test_faiss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="n">y_train_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># === Crear índice FAISS ===</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">faiss</span><span class="o">.</span><span class="n">IndexFlatL2</span><span class="p">(</span><span class="n">X_train_faiss</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># distancia euclidiana</span>
<span class="n">index</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X_train_faiss</span><span class="p">)</span>

<span class="c1"># === Buscar vecinos más cercanos con tiempo de cómputo ===</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># igual que el mejor k de KNN</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">X_test_faiss</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">elapsed_time_faiss</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (KNN con FAISS): </span><span class="si">{</span><span class="n">elapsed_time_faiss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Predicción: clase más frecuente entre vecinos ===</span>
<span class="n">y_pred_faiss</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">idx_list</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
    <span class="n">vecinos</span> <span class="o">=</span> <span class="n">y_train_array</span><span class="p">[</span><span class="n">idx_list</span><span class="p">]</span>
    <span class="n">pred_clase</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">vecinos</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>  <span class="c1"># clase más común</span>
    <span class="n">y_pred_faiss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_clase</span><span class="p">)</span>

<span class="c1"># === Evaluación ===</span>
<span class="n">acc_faiss</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_faiss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy con FAISS: </span><span class="si">{</span><span class="n">acc_faiss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report (FAISS) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_faiss</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tiempo de cómputo (KNN con FAISS): 243.8416 segundos
Accuracy con FAISS: 0.2202
=== Classification Report (FAISS) ===
              precision    recall  f1-score   support

      Centro       0.19      0.34      0.24     92131
       Norte       0.34      0.48      0.40     92131
   Occidente       0.16      0.16      0.16     92131
     Oriente       0.17      0.11      0.14     92132
         Sur       0.10      0.01      0.03     92131

    accuracy                           0.22    460656
   macro avg       0.19      0.22      0.19    460656
weighted avg       0.19      0.22      0.19    460656
</pre></div>
</div>
</div>
</div>
<p>Aunque FAISS es ampliamente reconocido por su eficiencia en búsquedas de vecinos en grandes volúmenes de datos, en este caso específico el uso de FAISS no redujo el tiempo de cómputo en comparación con el modelo KNN estándar. De hecho, el tiempo total fue significativamente mayor (243 segundos vs. 22 segundos (aprox)) debido a que se utilizó un índice exacto (IndexFlatL2) sin aprovechamiento de aceleración por GPU o aproximación. Esto nos ha resultado que, para datasets de tamaño moderado como el nuestro, las optimizaciones internas de scikit-learn como KD-Tree resulta más adecuada, aunque la diferencia en tiempo de computo no fue significativamente alta.</p>
</section>
</section>
<section id="optimizacion-de-bayes-con-partial-fit">
<h3><strong>Optimización de Bayes con Partial_fit</strong><a class="headerlink" href="#optimizacion-de-bayes-con-partial-fit" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Entrenamiento por lotes con partial_fit ---</span>
<span class="n">nb_batch_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
    <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">nb_batch_model</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nb_batch_model</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">batch_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de entrenamiento con partial_fit(): </span><span class="si">{</span><span class="n">batch_training_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># --- Evaluación ---</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb_batch_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_score</span> <span class="o">=</span> <span class="n">nb_batch_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Reporte de clasificación con nombres ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tiempo de entrenamiento con partial_fit(): 0.1582 segundos

Reporte de Clasificación:
              precision    recall  f1-score   support

      Centro       0.25      0.03      0.06     92131
       Norte       0.31      0.99      0.47     92131
   Occidente       0.19      0.02      0.03     92131
     Oriente       0.25      0.28      0.26     92132
         Sur       0.24      0.11      0.15     92131

    accuracy                           0.28    460656
   macro avg       0.25      0.28      0.19    460656
weighted avg       0.25      0.28      0.19    460656
</pre></div>
</div>
</div>
</div>
</section>
<section id="optimizacion-de-ridge-con-solver-optimizado-saga">
<h3><strong>Optimización de Ridge con Solver optimizado saga</strong><a class="headerlink" href="#optimizacion-de-ridge-con-solver-optimizado-saga" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>


<span class="c1"># === Codificar variable objetivo: LOCALITY ===</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY&#39;</span><span class="p">])</span>

<span class="c1"># === Seleccionar variables de entrada (X) ===</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;T2M&#39;</span><span class="p">,</span> <span class="s1">&#39;RH2M&#39;</span><span class="p">,</span> <span class="s1">&#39;PRECTOTCORR&#39;</span><span class="p">,</span> <span class="s1">&#39;WS10M&#39;</span><span class="p">,</span> <span class="s1">&#39;WD10M&#39;</span><span class="p">,</span>
            <span class="s1">&#39;PS&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_UV_INDEX&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_SW_DIFF&#39;</span><span class="p">,</span>
            <span class="s1">&#39;T2MDEW&#39;</span><span class="p">,</span> <span class="s1">&#39;T2MWET&#39;</span><span class="p">,</span> <span class="s1">&#39;WS50M&#39;</span><span class="p">,</span> <span class="s1">&#39;SolarIndex&#39;</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span>

<span class="c1"># === División train/test ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># === Escalar ===</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Definir modelo: Ridge (L2) ===</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span>
    <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span>      <span class="c1"># Ridge</span>
    <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">,</span>     <span class="c1"># Elegido automáticamente por sklearn</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>      
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>         
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># === Validación cruzada (accuracy) ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">ridge</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento final y predicción ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (Ridge): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Reporte de clasificación ===</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.28477995 0.28401706 0.28413801 0.28473941 0.28602795]
Promedio de accuracy en CV: 0.2847404750990643
Tiempo de cómputo (Ridge): 390.8309 segundos
=== Classification Report ===
              precision    recall  f1-score   support

      Centro       0.25      0.07      0.11     92131
       Norte       0.30      1.00      0.47     92131
   Occidente       0.25      0.18      0.21     92131
     Oriente       0.25      0.13      0.17     92132
         Sur       0.24      0.06      0.09     92131

    accuracy                           0.28    460656
   macro avg       0.26      0.28      0.21    460656
weighted avg       0.26      0.28      0.21    460656
</pre></div>
</div>
<img alt="../_images/33f7df2bbf176bf8bb688490e317de069e4b67ab979c146e1878849fc724b849.png" src="../_images/33f7df2bbf176bf8bb688490e317de069e4b67ab979c146e1878849fc724b849.png" />
<img alt="../_images/83bd47d2b3d8b8f4cc3334f23b1a56a21bea344aedb97183a30768dc7117f570.png" src="../_images/83bd47d2b3d8b8f4cc3334f23b1a56a21bea344aedb97183a30768dc7117f570.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC promedio (macro): 0.6005
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Matriz de Confusión ===</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlGnBu&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión - Ridge Logistic Regression (LOCALITY)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Curvas ROC por clase + AUC por clase ===</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">auc_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">):</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2"> (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adivinar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curvas ROC - Ridge Logistic Regression (LOCALITY)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Falsos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Verdaderos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># === AUC promedio (macro) ===</span>
<span class="n">auc_macro</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">auc_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC promedio (macro): </span><span class="si">{</span><span class="n">auc_macro</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="optimizacion-de-random-forest-con-gridsearchcv">
<h3><strong>Optimización de Random Forest con GridSearchCV</strong><a class="headerlink" href="#optimizacion-de-random-forest-con-gridsearchcv" title="Permalink to this heading">#</a></h3>
<p>El siguiente código implementa una versión optimizada del modelo Random Forest para la clasificación de la variable LOCALITY, utilizando una búsqueda exhaustiva de hiperparámetros mediante la técnica de GridSearchCV. A diferencia del modelo benchmark, que utiliza los valores por defecto del clasificador, esta versión explora sistemáticamente combinaciones de parámetros críticos como el número de árboles (n_estimators), la profundidad máxima de los árboles (max_depth), el número mínimo de muestras necesarias para dividir un nodo (min_samples_split), y el número mínimo de muestras por hoja (min_samples_leaf). Esta búsqueda se realiza con validación cruzada (cv=3), lo que permite evaluar el rendimiento de cada combinación de hiperparámetros de forma robusta, minimizando el riesgo de sobreajuste.</p>
<p>Una vez identificada la mejor configuración, el modelo resultante es evaluado sobre el conjunto de prueba, calculando métricas como accuracy, recall, precision, F1-score, matriz de confusión y AUC (curvas ROC por clase y macro). Además, se mide el tiempo total de entrenamiento para comparar la eficiencia del modelo optimizado respecto a su contraparte no ajustada. Con esto se busca que esta versión del modelo maximize el desempeño predictivo a través del ajuste sistemático de sus parámetros clave, en lugar de depender de la configuración por defecto</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># === Definir el modelo base ===</span>
<span class="n">rf_base</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Definir la grilla de hiperparámetros ===</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
    <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># === GridSearch con validación cruzada ===</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">rf_base</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="c1"># === Entrenamiento con tiempo ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de entrenamiento con GridSearch: </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Mejor modelo ===</span>
<span class="n">best_rf</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor combinación de hiperparámetros:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>

<span class="c1"># === Evaluación en test ===</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">best_rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Reporte</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 3 folds for each of 24 candidates, totalling 72 fits
Tiempo de entrenamiento con GridSearch: 96.89 segundos
Mejor combinación de hiperparámetros:
{&#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 2, &#39;min_samples_split&#39;: 2, &#39;n_estimators&#39;: 200}
Classification Report:
              precision    recall  f1-score   support

      Centro       0.25      0.17      0.20      4465
       Norte       0.37      0.87      0.51      4536
   Occidente       0.24      0.08      0.12      4513
     Oriente       0.26      0.27      0.26      4473
         Sur       0.24      0.14      0.18      4513

    accuracy                           0.31     22500
   macro avg       0.27      0.31      0.26     22500
weighted avg       0.27      0.31      0.26     22500
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Matriz de confusión</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlGnBu&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión - Random Forest (optimizado)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicción&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/77972f7d2d0809d09c16b0259d58dc317caa4ea88d81c00c8f91673e79e8528a.png" src="../_images/77972f7d2d0809d09c16b0259d58dc317caa4ea88d81c00c8f91673e79e8528a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Curvas ROC</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">auc_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">class_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">):</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">auc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2"> (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adivinar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Curvas ROC - Random Forest (optimizado)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Falsos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Verdaderos positivos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># AUC promedio</span>
<span class="n">auc_macro</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">auc_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">AUC promedio (macro): </span><span class="si">{</span><span class="n">auc_macro</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/274dbeb22e102cde7e1855cb0f6a9483cee8960a2958b383f011ead267795883.png" src="../_images/274dbeb22e102cde7e1855cb0f6a9483cee8960a2958b383f011ead267795883.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC promedio (macro): 0.6519
</pre></div>
</div>
</div>
</div>
</section>
<section id="svc-optimizado-con-sgdclassifier-linearsvc-rbf-svm-con-fourier">
<h3><strong>SVC optimizado con SGDClassifier,  LinearSVC, RBF SVM con Fourier</strong><a class="headerlink" href="#svc-optimizado-con-sgdclassifier-linearsvc-rbf-svm-con-fourier" title="Permalink to this heading">#</a></h3>
<section id="sgdclassifier">
<h4><strong>SGDClassifier</strong><a class="headerlink" href="#sgdclassifier" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># === Tomar la misma muestra de datos que SVC benchmark ===</span>
<span class="n">df_sampled</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">70000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Definir features y target ===</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;T2M&#39;</span><span class="p">,</span> <span class="s1">&#39;RH2M&#39;</span><span class="p">,</span> <span class="s1">&#39;PRECTOTCORR&#39;</span><span class="p">,</span> <span class="s1">&#39;WS10M&#39;</span><span class="p">,</span> <span class="s1">&#39;WD10M&#39;</span><span class="p">,</span>
            <span class="s1">&#39;PS&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_UV_INDEX&#39;</span><span class="p">,</span> <span class="s1">&#39;ALLSKY_SFC_SW_DIFF&#39;</span><span class="p">,</span>
            <span class="s1">&#39;T2MDEW&#39;</span><span class="p">,</span> <span class="s1">&#39;T2MWET&#39;</span><span class="p">,</span> <span class="s1">&#39;WS50M&#39;</span><span class="p">,</span> <span class="s1">&#39;SolarIndex&#39;</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_sampled</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_sampled</span><span class="p">[</span><span class="s1">&#39;LOCALITY_encoded&#39;</span><span class="p">]</span>

<span class="c1"># === División y escalado ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">SGDClassifier</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Definir modelo SGDClassifier como SVM (hinge loss) ===</span>
<span class="n">sgd_svm</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;hinge&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># === Validación cruzada (accuracy) ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">sgd_svm</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento y predicción (con tiempo) ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">sgd_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (SGDClassifier): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Predicción y métricas ===</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">sgd_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report (SGDClassifier) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.20693878 0.23938776 0.26377551 0.24765306 0.24877551]
Promedio de accuracy en CV: 0.2413061224489796
Tiempo de cómputo (SGDClassifier): 0.7831 segundos
=== Classification Report (SGDClassifier) ===
              precision    recall  f1-score   support

      Centro       0.21      0.35      0.27      4161
       Norte       0.32      0.07      0.12      4239
   Occidente       0.18      0.09      0.12      4196
     Oriente       0.18      0.37      0.25      4176
         Sur       0.25      0.16      0.20      4228

    accuracy                           0.21     21000
   macro avg       0.23      0.21      0.19     21000
weighted avg       0.23      0.21      0.19     21000
</pre></div>
</div>
</div>
</div>
</section>
<section id="linearsvc">
<h4><strong>LinearSVC</strong><a class="headerlink" href="#linearsvc" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearSVC</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Definir modelo LinearSVC ===</span>
<span class="n">linear_svc</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>

<span class="c1"># === Validación cruzada (accuracy) ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_svc</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento y predicción (con tiempo) ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">linear_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (LinearSVC): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Predicción y métricas ===</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">linear_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report (LinearSVC) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.28683673 0.28255102 0.27897959 0.28908163 0.29102041]
Promedio de accuracy en CV: 0.2856938775510204
Tiempo de cómputo (LinearSVC): 0.8366 segundos
=== Classification Report (LinearSVC) ===
              precision    recall  f1-score   support

      Centro       0.23      0.08      0.12      4161
       Norte       0.31      1.00      0.47      4239
   Occidente       0.22      0.06      0.09      4196
     Oriente       0.26      0.06      0.10      4176
         Sur       0.25      0.22      0.23      4228

    accuracy                           0.28     21000
   macro avg       0.25      0.28      0.20     21000
weighted avg       0.25      0.28      0.20     21000
</pre></div>
</div>
</div>
</div>
</section>
<section id="fourier">
<h4><strong>Fourier</strong><a class="headerlink" href="#fourier" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.kernel_approximation</span><span class="w"> </span><span class="kn">import</span> <span class="n">RBFSampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="c1"># === División y escalado ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># === Aproximación del kernel RBF con Fourier Features ===</span>
<span class="n">rbf_feature</span> <span class="o">=</span> <span class="n">RBFSampler</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">rbf_svm</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">rbf_feature</span><span class="p">,</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;hinge&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>

<span class="c1"># === Validación cruzada (accuracy) ===</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rbf_svm</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Promedio de accuracy en CV:&quot;</span><span class="p">,</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># === Entrenamiento y predicción (con tiempo) ===</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">rbf_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tiempo de cómputo (RBF SVM con Fourier): </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>

<span class="c1"># === Predicción y métricas ===</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rbf_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Classification Report (RBF SVM con Fourier) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.21867347 0.20653061 0.20785714 0.26142857 0.2494898 ]
Promedio de accuracy en CV: 0.22879591836734697
Tiempo de cómputo (RBF SVM con Fourier): 3.3366 segundos
=== Classification Report (RBF SVM con Fourier) ===
              precision    recall  f1-score   support

      Centro       0.24      0.40      0.30      4161
       Norte       0.31      1.00      0.47      4239
   Occidente       0.33      0.00      0.00      4196
     Oriente       0.25      0.02      0.03      4176
         Sur       0.55      0.00      0.00      4228

    accuracy                           0.28     21000
   macro avg       0.34      0.28      0.16     21000
weighted avg       0.34      0.28      0.16     21000
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="conclusiones">
<h2><strong>Conclusiones</strong><a class="headerlink" href="#conclusiones" title="Permalink to this heading">#</a></h2>
<p>Antes de comparar los modelos optimizados, es fundamental evaluar el rendimiento general de todos los modelos benchmark implementados. A continuación, se resume el desempeño de cada uno en términos de precisión, recall, exactitud, f1-score y AUC promedio. Esta tabla permite observar de forma clara cuáles modelos ofrecieron mejores resultados desde su configuración base y sirve como referencia para identificar aquellos con mayor potencial de mejora tras su optimización.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Modelo</p></th>
<th class="head"><p>precision</p></th>
<th class="head"><p>recall</p></th>
<th class="head"><p>accuracy</p></th>
<th class="head"><p>f1-score</p></th>
<th class="head"><p>AUC</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Clasificación Bayesiana</p></td>
<td><p>0.25</p></td>
<td><p>0.28</p></td>
<td><p>0.28</p></td>
<td><p>0.19</p></td>
<td><p>0.5862</p></td>
</tr>
<tr class="row-odd"><td><p>K-NN</p></td>
<td><p>0.19</p></td>
<td><p>0.22</p></td>
<td><p>0.22</p></td>
<td><p>0.19</p></td>
<td><p>0.5015</p></td>
</tr>
<tr class="row-even"><td><p>Ridge (L2)</p></td>
<td><p>0.26</p></td>
<td><p>0.28</p></td>
<td><p>0.28</p></td>
<td><p>0.21</p></td>
<td><p>0.6008</p></td>
</tr>
<tr class="row-odd"><td><p>Lasso (L1)</p></td>
<td><p>0.26</p></td>
<td><p>0.28</p></td>
<td><p>0.28</p></td>
<td><p>0.21</p></td>
<td><p>0.6007</p></td>
</tr>
<tr class="row-even"><td><p>Random Forest</p></td>
<td><p>0.12</p></td>
<td><p>0.16</p></td>
<td><p>0.16</p></td>
<td><p>0.13</p></td>
<td><p>0.4625</p></td>
</tr>
<tr class="row-odd"><td><p>XGBoost</p></td>
<td><p>0.23</p></td>
<td><p>0.28</p></td>
<td><p>0.28</p></td>
<td><p>0.22</p></td>
<td><p>0.6318</p></td>
</tr>
<tr class="row-even"><td><p>SVM</p></td>
<td><p>0.26</p></td>
<td><p>0.29</p></td>
<td><p>0.29</p></td>
<td><p>0.21</p></td>
<td><p>0.5886</p></td>
</tr>
</tbody>
</table>
<p>Al observar los resultados, se destaca que el modelo XGBoost presenta el mejor balance general entre métricas, con un AUC macro de 0.6318 y un f1-score ligeramente superior al resto. Le siguen los modelos Ridge y Lasso, que si bien empatan en precisión, recall y f1-score, muestran un AUC también competitivo (ambos en torno a 0.60), lo que sugiere una capacidad aceptable de diferenciación entre clases incluso sin ajustes adicionales.</p>
<p>El modelo Naive Bayes, a pesar de su simplicidad, logra un AUC de 0.5862 y una exactitud de 28 %, superando incluso a K-NN, que tuvo un rendimiento más bajo de forma general. Este último no logró destacarse en ninguna métrica clave, con valores cercanos al azar, lo que refleja sus limitaciones para capturar estructuras útiles en este conjunto de datos.</p>
<p>Random Forest, sorprendentemente, fue el modelo con desempeño más bajo, tanto en exactitud como en AUC (0.4625), evidenciando que su versión no optimizada no logró adaptarse bien a la naturaleza multiclase del problema. Por otro lado, el SVM, aunque fue entrenado con una muestra reducida por limitaciones computacionales, logró métricas similares a Ridge y Lasso, incluyendo el segundo mejor recall macro (0.29) y un AUC de 0.5886, lo que indica que, con más recursos o ajustes, podría ser una alternativa sólida.</p>
<p>Estos resultados iniciales marcan una base clara para analizar las mejoras introducidas por las versiones optimizadas de cada modelo.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="metodologia_modelos_regresion.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Modelos de Regresión</strong></p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Evaluacion y analisis de modelos, casos porblema de regresión y clasificación</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#librerias"><strong>Librerias:</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-de-clasificacion"><strong>MODELOS DE CLASIFICACIÓN</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#balanceo-de-clases"><strong>Balanceo de clases</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contextualizacion"><strong>Contextualización</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#verificacion-de-balance-de-clases"><strong>Verificación de balance de clases</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-benchmark"><strong>Modelos Benchmark</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion-de-los-modelos-sin-optimizacion"><strong>Implementación de los modelos (sin optimización)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knn-k-nearest-neighbors"><strong>KNN (K-Nearest Neighbors)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes"><strong>Bayes</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metrica-seleccionada"><strong>Métrica seleccionada</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge"><strong>Ridge</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso"><strong>Lasso</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest"><strong>Random Forest</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost"><strong>XGBoost</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-support-vector-machine"><strong>SVM (Support Vector Machine)</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion-de-los-modelos-con-optimizacion"><strong>Implementación de los modelos (con optimización)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizacion-de-knn-con-kd-trees-ball-trees-faiss"><strong>Optimización de KNN con KD-Trees, Ball Trees, FAISS</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#kd-tree"><strong>KD-Tree</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ball-trees"><strong>Ball Trees</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#faiss"><strong>FAISS</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizacion-de-bayes-con-partial-fit"><strong>Optimización de Bayes con Partial_fit</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizacion-de-ridge-con-solver-optimizado-saga"><strong>Optimización de Ridge con Solver optimizado saga</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizacion-de-random-forest-con-gridsearchcv"><strong>Optimización de Random Forest con GridSearchCV</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svc-optimizado-con-sgdclassifier-linearsvc-rbf-svm-con-fourier"><strong>SVC optimizado con SGDClassifier,  LinearSVC, RBF SVM con Fourier</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sgdclassifier"><strong>SGDClassifier</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#linearsvc"><strong>LinearSVC</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#fourier"><strong>Fourier</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones"><strong>Conclusiones</strong></a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Eliana Rodríguez - Jesús Arévalo
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>